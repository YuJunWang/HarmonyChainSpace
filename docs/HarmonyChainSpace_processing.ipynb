{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EsT902XUFo7x",
        "outputId": "9b06daf7-21ec-4723-966a-596397ab8cd4",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ç’°å¢ƒå®‰è£å®Œæˆï¼\n"
          ]
        }
      ],
      "source": [
        "# @title 1. å®‰è£ç›¸ä¾å¥—ä»¶ (Install Dependencies)\n",
        "!pip install -q -U \\\n",
        "  langchain-google-genai \\\n",
        "  langchain-groq \\\n",
        "  langchain-openai \\\n",
        "  langchain-core \\\n",
        "  langchain-community \\\n",
        "  langchain_huggingface \\\n",
        "  langchain-chroma \\\n",
        "  sentence-transformers \\\n",
        "  streamlit \\\n",
        "  pyngrok \\\n",
        "  pypdf \\\n",
        "  python-dotenv \\\n",
        "  beautifulsoup4\n",
        "\n",
        "print(\"âœ… ç’°å¢ƒå®‰è£å®Œæˆï¼\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2. è¨­å®š API Key\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "try:\n",
        "    # å˜—è©¦å¾ Colab Secrets è®€å–\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "    print(\"âœ… å·²å¾ Secrets è®€å– Google Gemini API Key\")\n",
        "except:\n",
        "    # å¦‚æœæ²’æœ‰è¨­å®š Secretsï¼Œå‰‡æ‰‹å‹•è¼¸å…¥\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = input(\"è«‹è¼¸å…¥æ‚¨çš„ Google Gemini API Key: \")\n",
        "\n",
        "\n",
        "try:\n",
        "    # å˜—è©¦å¾ Colab Secrets è®€å–\n",
        "    os.environ[\"HF_TOKEN\"] = userdata.get('HF_TOKEN')\n",
        "    print(\"âœ… å·²å¾ Secrets è®€å– HuggingFace API Key\")\n",
        "except:\n",
        "    # å¦‚æœæ²’æœ‰è¨­å®š Secretsï¼Œå‰‡æ‰‹å‹•è¼¸å…¥\n",
        "    os.environ[\"HF_TOKEN\"] = input(\"è«‹è¼¸å…¥æ‚¨çš„ HuggingFace API Key: \")\n",
        "\n",
        "\n",
        "try:\n",
        "    # å˜—è©¦å¾ Colab Secrets è®€å–\n",
        "    os.environ[\"GROQ_API_KEY\"] = userdata.get('GROQ_API_KEY')\n",
        "    print(\"âœ… å·²å¾ Secrets è®€å– GROQ API Key\")\n",
        "except:\n",
        "    # å¦‚æœæ²’æœ‰è¨­å®š Secretsï¼Œå‰‡æ‰‹å‹•è¼¸å…¥\n",
        "    os.environ[\"GROQ_API_KEY\"] = input(\"è«‹è¼¸å…¥æ‚¨çš„ GROQ API Key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3WC1z5YF4aK",
        "outputId": "a1918817-f14d-44a4-d7a4-4d4d181b827a",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… å·²å¾ Secrets è®€å– Google Gemini API Key\n",
            "âœ… å·²å¾ Secrets è®€å– HuggingFace API Key\n",
            "âœ… å·²å¾ Secrets è®€å– GROQ API Key\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3-1. çˆ¬å–å°ç£å¸¸ç”¨å»ºç¯‰æ³•è¦è³‡æ–™åº«\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "import re\n",
        "import time\n",
        "\n",
        "def scrape_full_building_code():\n",
        "    print(\"ğŸ•¸ï¸ æ­£åœ¨é€£ç·šè‡³å…¨åœ‹æ³•è¦è³‡æ–™åº«...\")\n",
        "\n",
        "    # ç›®æ¨™ï¼šå»ºç¯‰æŠ€è¡“è¦å‰‡å»ºç¯‰è¨­è¨ˆæ–½å·¥ç·¨ (PCode: D0070115)\n",
        "    # é€™æ˜¯å°ç£å®¤å…§è¨­è¨ˆæœ€ç›¸é—œçš„æ³•è¦\n",
        "    url = \"https://law.moj.gov.tw/LawClass/LawAll.aspx?pcode=D0070115\"\n",
        "\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers)\n",
        "        response.encoding = 'utf-8' # ç¢ºä¿ä¸­æ–‡ä¸äº‚ç¢¼\n",
        "\n",
        "        if response.status_code != 200:\n",
        "            print(f\"âŒ é€£ç·šå¤±æ•—ï¼Œç‹€æ…‹ç¢¼ï¼š{response.status_code}\")\n",
        "            return []\n",
        "\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "        # å°‹æ‰¾æ‰€æœ‰æ¢æ–‡å€å¡Š\n",
        "        # å…¨åœ‹æ³•è¦è³‡æ–™åº«çš„çµæ§‹é€šå¸¸æ˜¯ table æˆ– div row\n",
        "        # æˆ‘å€‘æŠ“å– class ç‚º \"law-reg-content\" ä¸‹çš„æ¯ä¸€è¡Œ\n",
        "        articles = []\n",
        "\n",
        "        # æŠ“å–æ¢è™Ÿ (col-no) èˆ‡ å…§å®¹ (col-data)\n",
        "        rows = soup.find_all(\"div\", class_=\"row\")\n",
        "\n",
        "        print(f\"ğŸ” æƒæåˆ° {len(rows)} å€‹å€å¡Šï¼Œæ­£åœ¨è§£æ...\")\n",
        "\n",
        "        for row in rows:\n",
        "            col_no = row.find(\"div\", class_=\"col-no\")\n",
        "            col_data = row.find(\"div\", class_=\"col-data\")\n",
        "\n",
        "            if col_no and col_data:\n",
        "                article_id = col_no.get_text(strip=True)\n",
        "                content = col_data.get_text(strip=True)\n",
        "\n",
        "                # éæ¿¾æ‰å»¢è©±ï¼Œåªç•™çœŸæ­£çš„æ¢æ–‡ (ä¾‹å¦‚ \"ç¬¬ 1 æ¢\")\n",
        "                if \"ç¬¬\" in article_id and \"æ¢\" in article_id:\n",
        "                    articles.append({\n",
        "                        \"ArticleNo\": article_id,\n",
        "                        \"ArticleContent\": content\n",
        "                    })\n",
        "\n",
        "        # å„²å­˜æˆ JSON æª”æ¡ˆ\n",
        "        filename = \"building_regulations_full.json\"\n",
        "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(articles, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "        print(f\"âœ… çˆ¬å–å®Œæˆï¼å…±å–å¾— {len(articles)} æ¢æ³•è¦ã€‚\")\n",
        "        print(f\"ğŸ“‚ æª”æ¡ˆå·²å„²å­˜ç‚ºï¼š{filename}\")\n",
        "\n",
        "        # é¡¯ç¤ºå‰ 3 æ¢çœ‹çœ‹\n",
        "        print(\"\\n--- é è¦½å‰ 3 æ¢ ---\")\n",
        "        for art in articles[:3]:\n",
        "            print(f\"{art['ArticleNo']}: {art['ArticleContent'][:50]}...\")\n",
        "\n",
        "        return filename\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        return None\n",
        "\n",
        "# åŸ·è¡Œçˆ¬èŸ²\n",
        "json_file = scrape_full_building_code()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IxeEdidMKBL",
        "outputId": "afd8724c-4056-4537-a14a-f6324f866672",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ•¸ï¸ æ­£åœ¨é€£ç·šè‡³å…¨åœ‹æ³•è¦è³‡æ–™åº«...\n",
            "ğŸ” æƒæåˆ° 390 å€‹å€å¡Šï¼Œæ­£åœ¨è§£æ...\n",
            "âœ… çˆ¬å–å®Œæˆï¼å…±å–å¾— 389 æ¢æ³•è¦ã€‚\n",
            "ğŸ“‚ æª”æ¡ˆå·²å„²å­˜ç‚ºï¼šbuilding_regulations_full.json\n",
            "\n",
            "--- é è¦½å‰ 3 æ¢ ---\n",
            "æœ¬æ¢æ–‡æœ‰é™„ä»¶ç¬¬ 1 æ¢: æœ¬ç·¨å»ºç¯‰æŠ€è¡“ç”¨èªï¼Œå…¶ä»–å„ç·¨å¾—é©ç”¨ï¼Œå…¶å®šç¾©å¦‚ä¸‹ï¼šä¸€ã€ä¸€å®—åœŸåœ°ï¼šæœ¬æ³•ç¬¬åä¸€æ¢æ‰€ç¨±ä¸€å®—åœŸåœ°ï¼ŒæŒ‡ä¸€å¹¢æˆ–äºŒå¹¢ä»¥...\n",
            "æœ¬æ¢æ–‡æœ‰é™„ä»¶ç¬¬ 2 æ¢: åŸºåœ°æ‡‰èˆ‡å»ºç¯‰ç·šç›¸é€£æ¥ï¼Œå…¶é€£æ¥éƒ¨ä»½ä¹‹æœ€å°é•·åº¦æ‡‰åœ¨äºŒå…¬å°ºä»¥ä¸Šã€‚åŸºåœ°å…§ç§è¨­é€šè·¯ä¹‹å¯¬åº¦ä¸å¾—å°æ–¼å·¦åˆ—æ¨™æº–ï¼šä¸€ã€...\n",
            "ç¬¬ 2-1 æ¢: ç§è¨­é€šè·¯é•·åº¦è‡ªå»ºç¯‰ç·šèµ·ç®—æœªè¶…éä¸‰åäº”å…¬å°ºéƒ¨åˆ†ï¼Œå¾—è¨ˆå…¥æ³•å®šç©ºåœ°é¢ç©ã€‚...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3-2. å»ºæ§‹å½¢å®¶æ ¼å±€ç›¸é—œå­¸èªªè³‡æ–™åº«\n",
        "\n",
        "import json\n",
        "\n",
        "def create_comprehensive_fengshui_dataset():\n",
        "    print(\"ğŸ“¦ æ­£åœ¨æ§‹å»ºã€Šé™½å®…ä¸‰è¦ã€‹ã€ã€Šé™½å®…åæ›¸ã€‹ã€ã€Šé­¯ç­ç¶“ã€‹æ ¸å¿ƒé€šç”¨è³‡æ–™åº«...\")\n",
        "\n",
        "    # é€™ä»½è³‡æ–™é›†å°ˆæ³¨æ–¼ã€Œé€šç”¨æ€§ã€èˆ‡ã€Œç¾ä»£æ ¼å±€ã€ï¼Œä¸è«‡è¤‡é›œçš„ç¾…ç›¤æ–¹ä½\n",
        "    dataset = [\n",
        "        # ===============================================================\n",
        "        # ğŸ”¥ ç¬¬ä¸€å–®å…ƒï¼šå»šæˆ¿ç¯‡ (ç¶) - é¤Šå‘½ä¹‹æº\n",
        "        # æ ¸å¿ƒç¶“å…¸ï¼šã€Šé™½å®…ä¸‰è¦ã€‹\n",
        "        # ===============================================================\n",
        "        {\n",
        "            \"Book\": \"é™½å®…ä¸‰è¦\",\n",
        "            \"Topic\": \"é–‹é–€è¦‹ç¶\",\n",
        "            \"Content\": \"é–‹é–€è¦‹ç¶ï¼ŒéŒ¢è²¡å¤šè€—ã€‚å¤§é–€ç‚ºç´æ°£ä¹‹å£ï¼Œç¶ç‚ºè²¡åº«ä¹‹è±¡ã€‚è‹¥ä¸€é€²é–€å³è¦‹ç“¦æ–¯çˆï¼Œä¸»è²¡æ°£å¤–éœ²ï¼Œå®¶é‹ä¸èšï¼Œä¸”æ˜“ç”Ÿå£è§’ã€‚\"\n",
        "        },\n",
        "        {\n",
        "            \"Book\": \"é™½å®…ä¸‰è¦\",\n",
        "            \"Topic\": \"æ°´ç«ä¸å®¹\",\n",
        "            \"Content\": \"ç¶ä½ä¸å¯èˆ‡æ°´æ§½ç·Šé„°ï¼Œäº¦ä¸å¯ç›¸å°ã€‚ç¶å±¬ç«ï¼Œæ°´æ§½å±¬æ°´ï¼Œæ°´ç«ç›¸æˆ°ï¼Œä¸»å¥³ä¸»äººå¤šç—…ï¼Œå¤«å¦»æ˜“ç”Ÿå£è§’ã€‚ä¸­é–“å®œæœ‰æ–™ç†å°ç·©è¡ã€‚\"\n",
        "        },\n",
        "        {\n",
        "            \"Book\": \"é­¯ç­ç¶“\",\n",
        "            \"Topic\": \"æ¨è»Šç¶\",\n",
        "            \"Content\": \"å»šæˆ¿ä¸å¯è¨­æ–¼æˆ¿å­æœ€å‰æ–¹ï¼ˆè¿‘å¤§é–€è™•ï¼‰ï¼Œåç‚ºã€æ¨è»Šç¶ã€ï¼Œä¸»å®¶å£ä¸å’Œï¼Œé‹å‹¢é€€æ•—ã€‚å»šæˆ¿å®œè—æ–¼å±‹å¾Œã€‚\"\n",
        "        },\n",
        "        {\n",
        "            \"Book\": \"é™½å®…åæ›¸\",\n",
        "            \"Topic\": \"æ©«æ¨‘å£“ç¶\",\n",
        "            \"Content\": \"ç¶å°ä¸Šæ–¹ä¸å¯æœ‰æ©«æ¨‘å£“é ‚ã€‚ç¶ä¸»é£Ÿç¥¿ï¼Œè‹¥å—å£“ï¼Œä¸»å¥³ä¸»äººå¥åº·å—æï¼Œå®¶ä¸­è²¡é‹å—é˜»ã€‚\"\n",
        "        },\n",
        "        {\n",
        "            \"Book\": \"é™½å®…ä¸‰è¦\",\n",
        "            \"Topic\": \"å»šæˆ¿ç„¡é \",\n",
        "            \"Content\": \"ç“¦æ–¯çˆå¾Œæ–¹ä¸å¯æ˜¯çª—æˆ¶ï¼Œåç‚ºã€èƒŒå¾Œç©ºè™›ã€ï¼Œä¸»æ¼è²¡ã€‚ç¶å¾Œå®œé å¯¦ç‰†ï¼Œè±¡å¾µæœ‰é å±±ã€‚\"\n",
        "        },\n",
        "\n",
        "        # ===============================================================\n",
        "        # ğŸšª ç¬¬äºŒå–®å…ƒï¼šå¤§é–€èˆ‡ç„é—œç¯‡ (é–€) - ç´æ°£ä¹‹å£\n",
        "        # æ ¸å¿ƒç¶“å…¸ï¼šã€Šé™½å®…åæ›¸ã€‹ã€ã€Šé­¯ç­ç¶“ã€‹\n",
        "        # ===============================================================\n",
        "        {\n",
        "            \"Book\": \"é™½å®…åæ›¸\",\n",
        "            \"Topic\": \"ç©¿å ‚ç…\",\n",
        "            \"Content\": \"å¤§é–€ç›´é€šå¾Œé–€ï¼Œæˆ–å¤§é–€æ­£å°è½åœ°çª—ï¼Œä¸­é–“ç„¡é®æ“‹ï¼Œåç‚ºã€ç©¿å ‚ç…ã€ã€‚æ°£æµç›´å…¥ç›´å‡ºï¼Œä¸»è²¡ä¾†è²¡å»ï¼Œç„¡æ³•èšè²¡ã€‚\"\n",
        "        },\n",
        "        {\n",
        "            \"Book\": \"é­¯ç­ç¶“\",\n",
        "            \"Topic\": \"å…©é–€ç›¸å°\",\n",
        "            \"Content\": \"äºŒå®¶ä¸å¯é–€ç›¸å°ï¼Œå¿…ä¸»ä¸€å®¶é€€ï¼›è‡ªå®¶æˆ¿é–€ä¸å¯ç›¸å°ï¼Œåç‚ºã€ç½µé–€ã€ï¼Œä¸»å®¶ä¸­å£èˆŒæ˜¯éå¤šã€‚å®œè¨­é–€ç°¾æˆ–å±é¢¨åŒ–è§£ã€‚\"\n",
        "        },\n",
        "        {\n",
        "            \"Book\": \"é™½å®…ä¸‰è¦\",\n",
        "            \"Topic\": \"é–‹é–€è¦‹å»\",\n",
        "            \"Content\": \"å¤§é–€ä¸€é–‹å³è¦‹å»æ‰€é–€ï¼Œç©¢æ°£è¿äººï¼Œä¸»è²´äººä¸è‡¨ï¼Œè²¡ç¥ä¸å…¥ã€‚ä¸”ä¸»èº«é«”å¤šç—…ç—›ã€‚\"\n",
        "        },\n",
        "        {\n",
        "            \"Book\": \"é™½å®…åæ›¸\",\n",
        "            \"Topic\": \"é–‹é–€è¦‹é¡\",\n",
        "            \"Content\": \"ç„é—œä¸å¯æ­£å°å¤§é¡å­ã€‚é¡å­æœƒåå°„æ°£å ´ï¼Œå°‡å¤§é–€å¸ç´ä¹‹å‰æ°£åå°„å‡ºå»ï¼Œä¸»æ¼è²¡ã€é‹å‹¢ä¸é †ã€‚\"\n",
        "        },\n",
        "        {\n",
        "            \"Book\": \"é­¯ç­ç¶“\",\n",
        "            \"Topic\": \"æ‹±é–€ç…\",\n",
        "            \"Content\": \"å®¶å…§é–€å½¢ä¸å¯åšæˆåœ“å¼§æ‹±é–€ç‹€ï¼Œåç‚ºã€é©›é¦¬ã€æˆ–ã€ç‰›è»›ã€ï¼Œä¸»å®¶äººå‹ç¢Œå¥”æ³¢ï¼Œç•™ä¸ä½äººã€‚\"\n",
        "        },\n",
        "\n",
        "        # ===============================================================\n",
        "        # ğŸ›ï¸ ç¬¬ä¸‰å–®å…ƒï¼šè‡¥å®¤ç¯‡ (ä¸») - é¤Šæ°£ä¹‹æ‰€\n",
        "        # æ ¸å¿ƒç¶“å…¸ï¼šã€Šé™½å®…ä¸‰è¦ã€‹ã€ã€Šé­¯ç­ç¶“ã€‹\n",
        "        # ===============================================================\n",
        "        {\n",
        "            \"Book\": \"é­¯ç­ç¶“\",\n",
        "            \"Topic\": \"æ©«æ¨‘å£“åºŠ\",\n",
        "            \"Content\": \"åºŠé ­æˆ–åºŠé‹ªä¸Šæ–¹ä¸å¯æœ‰æ©«æ¨‘ã€‚æ¨‘å£“é ­ï¼Œä¸»é ­ç—›ã€å¤±çœ ï¼›æ¨‘å£“èƒ¸ï¼Œä¸»æ°£æ‚¶ï¼›æ¨‘å£“è…³ï¼Œä¸»è…³ç–¾ã€‚æ­¤ç‚ºé™½å®…å¤§å¿Œã€‚\"\n",
        "        },\n",
        "        {\n",
        "            \"Book\": \"é™½å®…ä¸‰è¦\",\n",
        "            \"Topic\": \"åºŠé ­ç„¡é \",\n",
        "            \"Content\": \"åºŠé ­å®œå¯¦ä¸å®œè™›ã€‚åºŠé ­ä¸å¯é çª—ï¼Œä¸å¯æ‡¸ç©ºï¼Œä¸å¯èƒŒå°æˆ¿é–€ã€‚ç„¡é ä¸»å¿ƒç¥ä¸å¯§ï¼Œæ˜“çŠ¯å°äººï¼Œç¡çœ å“è³ªå·®ã€‚\"\n",
        "        },\n",
        "        {\n",
        "            \"Book\": \"é™½å®…åæ›¸\",\n",
        "            \"Topic\": \"é¡å­å°åºŠ\",\n",
        "            \"Content\": \"è‡¥å®¤å…§é¡å­ä¸å¯æ­£å°åºŠé‹ªã€‚åŠå¤œèµ·èº«æ˜“å—é©šåš‡ï¼Œä¸”é¡å­æ”é­‚ï¼Œä¸»ç¥ç¶“è¡°å¼±ï¼Œå¤«å¦»ä¸å’Œã€‚\"\n",
        "        },\n",
        "        {\n",
        "            \"Book\": \"é™½å®…ä¸‰è¦\",\n",
        "            \"Topic\": \"å»æ²–åºŠ\",\n",
        "            \"Content\": \"å»æ‰€é–€ä¸å¯æ­£å°åºŠä½ã€‚å»æ‰€ç‚ºå­¤é™°ç©¢æ°£ä¹‹åœ°ï¼Œæ²–é ­ä¸»é ­ç—…ï¼Œæ²–è…°ä¸»è…°ç—…ã€‚å®œæ”¹é–€å‘æˆ–è¨­éš±å½¢é–€ã€‚\"\n",
        "        },\n",
        "        {\n",
        "            \"Book\": \"é­¯ç­ç¶“\",\n",
        "            \"Topic\": \"å£åˆ€åˆ‡åºŠ\",\n",
        "            \"Content\": \"æˆ¿å…§æŸ±å­å°–è§’ä¸å¯æ²–å°„åºŠä½ï¼Œåç‚ºã€å£åˆ€ç…ã€ï¼Œä¸»è¡€å…‰ã€é–‹åˆ€ã€‚å®œç”¨è¡£æ«ƒå¡«å¹³æˆ–åœ“å¼§åŒ…è¦†ã€‚\"\n",
        "        },\n",
        "\n",
        "        # ===============================================================\n",
        "        # ğŸš½ ç¬¬å››å–®å…ƒï¼šè¡›æµ´ç¯‡ - ç©¢æ°£ä¹‹æº\n",
        "        # æ ¸å¿ƒç¶“å…¸ï¼šã€Šé™½å®…åæ›¸ã€‹\n",
        "        # ===============================================================\n",
        "        {\n",
        "            \"Book\": \"é™½å®…åæ›¸\",\n",
        "            \"Topic\": \"ä¸­å®®é€ å»\",\n",
        "            \"Content\": \"æˆ¿å­æ­£ä¸­å¤®ï¼ˆä¸­å®®ï¼‰ä¸å¯è¨­å»æ‰€ã€‚ä¸­å®®å¦‚äººä¹‹å¿ƒè‡Ÿï¼Œå®œæ·¨å®œäº®ã€‚å»å…¥ä¸­å®®ï¼Œåç‚ºã€ç©¢æ°£å…¥å¿ƒã€ï¼Œä¸»å¿ƒè‡Ÿç–¾ç—…ï¼Œå®¶é‹è¡°é€€ã€‚\"\n",
        "        },\n",
        "        {\n",
        "            \"Book\": \"é™½å®…ä¸‰è¦\",\n",
        "            \"Topic\": \"å»æ‰€å±…é«˜\",\n",
        "            \"Content\": \"è‹¥ç‚ºé€å¤©æˆ–æ¨“ä¸­æ¨“ï¼Œå»æ‰€ä¸å¯è¨­æ–¼ç¥æ˜å»³æˆ–å¤§é–€ä¸Šæ–¹ï¼Œåç‚ºã€æ·‹é ­æ°´ã€ï¼Œä¸»å¾Œä»£ä¸æ•¬ï¼Œé‹å‹¢å—å£“ã€‚\"\n",
        "        },\n",
        "        {\n",
        "            \"Book\": \"é™½å®…åæ›¸\",\n",
        "            \"Topic\": \"å»æ‰€å°é¤æ¡Œ\",\n",
        "            \"Content\": \"å»æ‰€é–€ä¸å¯æ­£å°é¤æ¡Œã€‚é€²é£Ÿä¹‹åœ°å®œæ½”ï¼Œç©¢æ°£ç›´æ²–ï¼Œä¸»è…¸èƒƒç–¾ç—…ï¼Œäº¦å½±éŸ¿é£Ÿæ…¾ã€‚\"\n",
        "        },\n",
        "\n",
        "        # ===============================================================\n",
        "        # ğŸ  ç¬¬äº”å–®å…ƒï¼šå½¢ç…èˆ‡å…¶ä»– (æ¨‘ã€æŸ±ã€å…‰)\n",
        "        # æ ¸å¿ƒç¶“å…¸ï¼šã€Šé­¯ç­ç¶“ã€‹\n",
        "        # ===============================================================\n",
        "        {\n",
        "            \"Book\": \"é­¯ç­ç¶“\",\n",
        "            \"Topic\": \"å»³ä¸­æ©«æ¨‘\",\n",
        "            \"Content\": \"å®¢å»³æ²™ç™¼ä¸Šæ–¹ä¸å¯æœ‰æ©«æ¨‘ï¼Œä¸»ä¸€å®¶ä¹‹ä¸»å£“åŠ›å¤§ï¼Œé‹å‹¢å—é˜»ã€‚è‹¥ç„¡æ³•é¿é–‹ï¼Œæ‡‰ç”¨å¤©èŠ±æ¿åŒ…è¦†å¹³æ•´ã€‚\"\n",
        "        },\n",
        "        {\n",
        "            \"Book\": \"é™½å®…åæ›¸\",\n",
        "            \"Topic\": \"å¤©æ–¬ç…\",\n",
        "            \"Content\": \"çª—å¤–ä¸å¯è¦‹å…©æ£Ÿå¤§æ¨“ä¸­é–“ä¹‹ç´°ç¸«ï¼Œåç‚ºã€å¤©æ–¬ç…ã€ï¼Œä¸»è¡€å…‰ã€æ„å¤–ã€‚å®œæ›å±±æµ·é®æˆ–åšçª—ç°¾é®æ“‹ã€‚\"\n",
        "        },\n",
        "        {\n",
        "            \"Book\": \"é­¯ç­ç¶“\",\n",
        "            \"Topic\": \"å°–è§’æ²–å°„\",\n",
        "            \"Content\": \"å±‹å…§ä¸å¯æœ‰å°–éŠ³ç‰†è§’å°æ²–æ²™ç™¼æˆ–åº§ä½ï¼Œä¸»çŠ¯å°äººã€å£è§’ã€‚å®œæ“ºæ”¾ç›†æ ½åŒ–è§£ã€‚\"\n",
        "        },\n",
        "        {\n",
        "            \"Book\": \"ç¾ä»£å½¢å®¶\",\n",
        "            \"Topic\": \"æ²™ç™¼ç„¡é \",\n",
        "            \"Content\": \"å®¢å»³ä¸»æ²™ç™¼èƒŒå¾Œå®œæœ‰å¯¦ç‰†ï¼Œè±¡å¾µæœ‰é å±±ã€‚ä¸å¯èƒŒå°å¤§é–€ï¼Œä¸å¯èƒŒå°èµ°é“ï¼Œä¸å¯èƒŒå°çª—æˆ¶ï¼Œå¦å‰‡ä¸»è²´äººä¸é¡¯ï¼ŒçŠ¯å°äººã€‚\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # å­˜æª”\n",
        "    filename = \"general_fengshui_full.json\"\n",
        "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(dataset, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "    print(f\"âœ… è³‡æ–™åº«é‡æ§‹å®Œæˆï¼å·²æ”¶éŒ„ {len(dataset)} æ¢ã€é«˜é€šç”¨æ€§ã€‘å½¢å®¶é¢¨æ°´æ³•å‰‡ã€‚\")\n",
        "    print(f\"ğŸ“‚ æª”æ¡ˆä½ç½®ï¼š{filename}\")\n",
        "    return filename\n",
        "\n",
        "# åŸ·è¡Œå»ºç«‹\n",
        "json_file = create_comprehensive_fengshui_dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbkM6P5xq4Vm",
        "outputId": "5fc8fd54-6bdf-4afa-b701-b000317a27b0",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¦ æ­£åœ¨æ§‹å»ºã€Šé™½å®…ä¸‰è¦ã€‹ã€ã€Šé™½å®…åæ›¸ã€‹ã€ã€Šé­¯ç­ç¶“ã€‹æ ¸å¿ƒé€šç”¨è³‡æ–™åº«...\n",
            "âœ… è³‡æ–™åº«é‡æ§‹å®Œæˆï¼å·²æ”¶éŒ„ 22 æ¢ã€é«˜é€šç”¨æ€§ã€‘å½¢å®¶é¢¨æ°´æ³•å‰‡ã€‚\n",
            "ğŸ“‚ æª”æ¡ˆä½ç½®ï¼šgeneral_fengshui_full.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "INPUT_FILE = \"general_fengshui_full.json\"\n",
        "OUTPUT_FILE = \"fengshui_refined_gold.json\"\n",
        "\n",
        "class RefinedFengShui(BaseModel):\n",
        "    modern_title: str = Field(description=\"ç¾ä»£åŒ–çš„ç°¡çŸ­æ¨™é¡Œï¼Œä¾‹å¦‚ï¼šé–‹é–€è¦‹ç¶çš„åŒ–è§£\")\n",
        "    original_text: str = Field(description=\"å¤ç±çš„å®Œæ•´åŸæ–‡å…§å®¹\")\n",
        "    plain_explanation: str = Field(description=\"è©³ç´°çš„ç™½è©±æ–‡è§£é‡‹ï¼Œèªªæ˜ç‚ºä½•ä¸å¥½\")\n",
        "    actionable_advice: str = Field(description=\"ç¾ä»£å®¤å…§è¨­è¨ˆçš„å…·é«”è§£æ±ºæ–¹æ¡ˆï¼ˆå¦‚ï¼šå±é¢¨ã€éš±è—é–€ã€ç¶ æ¤ï¼‰\")\n",
        "    tags: str = Field(description=\"é—œéµå­—æ¨™ç±¤\")\n",
        "\n",
        "def run_comprehensive_refinery():\n",
        "    print(\"ğŸ­ å•Ÿå‹• Groq ç…‰æ²¹å»  (è™•ç†é€šç”¨å½¢å®¶è³‡æ–™)...\")\n",
        "\n",
        "    with open(INPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "        raw_data = json.load(f)\n",
        "\n",
        "    if not os.environ.get(\"GROQ_API_KEY\"):\n",
        "         print(\"âŒ ç¼º Groq Key\")\n",
        "         return\n",
        "\n",
        "    # GROQ_MODEL = \"llama-3.1-8b-instant\"\n",
        "    GROQ_MODEL = \"llama-3.3-70b-versatile\"\n",
        "\n",
        "    llm = ChatGroq(\n",
        "        temperature=0.1,\n",
        "        model_name=GROQ_MODEL,\n",
        "        groq_api_key=os.environ.get(\"GROQ_API_KEY\")\n",
        "    )\n",
        "\n",
        "    parser = JsonOutputParser(pydantic_object=RefinedFengShui)\n",
        "    refined_data = []\n",
        "\n",
        "    print(f\"ğŸ“¦ æº–å‚™æç…‰ {len(raw_data)} æ¢è³‡æ–™...\")\n",
        "\n",
        "    for i, item in enumerate(raw_data):\n",
        "        print(f\"   âš™ï¸ åŠ å·¥ä¸­ ({i+1}/{len(raw_data)}): {item['Topic']}...\")\n",
        "\n",
        "        template = \"\"\"\n",
        "        ä½ æ˜¯ç¾ä»£å®¤å…§è¨­è¨ˆèˆ‡é¢¨æ°´å°ˆå®¶ã€‚è«‹å°‡ä»¥ä¸‹è³‡æ–™è½‰åŒ–ç‚ºçµæ§‹åŒ–çŸ¥è­˜ã€‚\n",
        "\n",
        "        ä¸»é¡Œï¼š{topic}\n",
        "        å¤ç±ï¼š{book}\n",
        "        å…§å®¹ï¼š{content}\n",
        "\n",
        "        ä»»å‹™ï¼š\n",
        "        1. ã€è§£é‡‹ã€‘ï¼šç”¨ç™½è©±æ–‡è§£é‡‹æ­¤ç¦å¿Œçš„é‚è¼¯ï¼ˆå¿ƒç†å­¸æˆ–æ°£å ´å­¸ã€å½¢å­¸ã€ç†å‰‡æ´¾ï¼‰ã€‚\n",
        "        2. ã€å»ºè­°ã€‘ï¼šæä¾› 2-3 ç¨®ç¾ä»£è£ä¿®ã€æˆ–æ˜¯é¢¨æ°´ä¸Šçš„åŒ–è§£æ³•ï¼ˆä¸è¦è¿·ä¿¡ç¬¦å’’ï¼Œè¦ç”¨è¨­è¨ˆæ‰‹æ³•ï¼‰ã€‚\n",
        "        3. ã€æ¨™ç±¤ã€‘ï¼šæå–é—œéµå­—ã€‚\n",
        "\n",
        "        {format_instructions}\n",
        "        \"\"\"\n",
        "        prompt = ChatPromptTemplate.from_template(template, partial_variables={\"format_instructions\": parser.get_format_instructions()})\n",
        "        chain = prompt | llm | parser\n",
        "\n",
        "        try:\n",
        "            result = chain.invoke({\"topic\": item['Topic'], \"book\": item['Book'], \"content\": item['Content']})\n",
        "            result['source_book'] = item['Book']\n",
        "            refined_data.append(result)\n",
        "        except Exception as e:\n",
        "            print(f\"   âš ï¸ è·³é: {e}\")\n",
        "\n",
        "    with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(refined_data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "    print(f\"\\nâœ¨ ç…‰æ²¹å®Œæˆï¼ç”¢å‡º {len(refined_data)} æ¢é»ƒé‡‘è³‡æ–™ã€‚\")\n",
        "    return OUTPUT_FILE\n",
        "\n",
        "# åŸ·è¡Œ\n",
        "gold_file = run_comprehensive_refinery()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gm5As0dq51R",
        "outputId": "471b4dd9-f884-4118-b0cf-f237dace2c11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ­ å•Ÿå‹• Groq ç…‰æ²¹å»  (è™•ç†é€šç”¨å½¢å®¶è³‡æ–™)...\n",
            "ğŸ“¦ æº–å‚™æç…‰ 22 æ¢è³‡æ–™...\n",
            "   âš™ï¸ åŠ å·¥ä¸­ (1/22): é–‹é–€è¦‹ç¶...\n",
            "   âš™ï¸ åŠ å·¥ä¸­ (2/22): æ°´ç«ä¸å®¹...\n",
            "   âš™ï¸ åŠ å·¥ä¸­ (3/22): æ¨è»Šç¶...\n",
            "   âš™ï¸ åŠ å·¥ä¸­ (4/22): æ©«æ¨‘å£“ç¶...\n",
            "   âš™ï¸ åŠ å·¥ä¸­ (5/22): å»šæˆ¿ç„¡é ...\n",
            "   âš™ï¸ åŠ å·¥ä¸­ (6/22): ç©¿å ‚ç…...\n",
            "   âš™ï¸ åŠ å·¥ä¸­ (7/22): å…©é–€ç›¸å°...\n",
            "   âš™ï¸ åŠ å·¥ä¸­ (8/22): é–‹é–€è¦‹å»...\n",
            "   âš™ï¸ åŠ å·¥ä¸­ (9/22): é–‹é–€è¦‹é¡...\n",
            "   âš™ï¸ åŠ å·¥ä¸­ (10/22): æ‹±é–€ç…...\n",
            "   âš™ï¸ åŠ å·¥ä¸­ (11/22): æ©«æ¨‘å£“åºŠ...\n",
            "   âš™ï¸ åŠ å·¥ä¸­ (12/22): åºŠé ­ç„¡é ...\n",
            "   âš™ï¸ åŠ å·¥ä¸­ (13/22): é¡å­å°åºŠ...\n",
            "   âš™ï¸ åŠ å·¥ä¸­ (14/22): å»æ²–åºŠ...\n",
            "   âš™ï¸ åŠ å·¥ä¸­ (15/22): å£åˆ€åˆ‡åºŠ...\n",
            "   âš™ï¸ åŠ å·¥ä¸­ (16/22): ä¸­å®®é€ å»...\n",
            "   âš™ï¸ åŠ å·¥ä¸­ (17/22): å»æ‰€å±…é«˜...\n",
            "   âš™ï¸ åŠ å·¥ä¸­ (18/22): å»æ‰€å°é¤æ¡Œ...\n",
            "   âš™ï¸ åŠ å·¥ä¸­ (19/22): å»³ä¸­æ©«æ¨‘...\n",
            "   âš™ï¸ åŠ å·¥ä¸­ (20/22): å¤©æ–¬ç…...\n",
            "   âš™ï¸ åŠ å·¥ä¸­ (21/22): å°–è§’æ²–å°„...\n",
            "   âš™ï¸ åŠ å·¥ä¸­ (22/22): æ²™ç™¼ç„¡é ...\n",
            "\n",
            "âœ¨ ç…‰æ²¹å®Œæˆï¼ç”¢å‡º 22 æ¢é»ƒé‡‘è³‡æ–™ã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "def fix_json_keys():\n",
        "    file_path = \"fengshui_refined_gold.json\"\n",
        "\n",
        "    if not os.path.exists(file_path):\n",
        "        print(\"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆï¼\")\n",
        "        return\n",
        "\n",
        "    print(f\"ğŸ•µï¸â€â™‚ï¸ æ­£åœ¨æª¢æŸ¥ {file_path} çš„å…§å®¹çµæ§‹...\")\n",
        "\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        try:\n",
        "            data = json.load(f)\n",
        "        except json.JSONDecodeError:\n",
        "            print(\"âŒ JSON æ ¼å¼ææ¯€ï¼Œ8B å¯èƒ½å¯«å…¥äº†ç„¡æ•ˆçš„æ ¼å¼ã€‚å»ºè­°é‡æ–°ç”Ÿæˆã€‚\")\n",
        "            return\n",
        "\n",
        "    if not data:\n",
        "        print(\"âŒ æª”æ¡ˆæ˜¯ç©ºçš„ï¼\")\n",
        "        return\n",
        "\n",
        "    # 1. å·çœ‹ç¬¬ä¸€ç­†è³‡æ–™é•·æ€æ¨£\n",
        "    first_item = data[0]\n",
        "    print(\"\\nğŸ“ ç¬¬ä¸€ç­†è³‡æ–™çš„ Keys :\")\n",
        "    print(list(first_item.keys()))\n",
        "\n",
        "    # 2. å®šç¾©å¸¸è¦‹çš„éŒ¯èª¤æ˜ å°„è¡¨ (æ ¹æ“šç¶“é©—ï¼Œ8B å¸¸çŠ¯é€™äº›éŒ¯)\n",
        "    # å·¦é‚Šæ˜¯ 8B å¯èƒ½å¯«éŒ¯çš„ï¼Œå³é‚Šæ˜¯æˆ‘å€‘æ¨™æº–çš„\n",
        "    key_mapping = {\n",
        "        \"æ¨™é¡Œ\": \"modern_title\",\n",
        "        \"ç¾ä»£æ¨™é¡Œ\": \"modern_title\",\n",
        "        \"Title\": \"modern_title\",\n",
        "        \"topic\": \"modern_title\",\n",
        "\n",
        "        \"åŸæ–‡\": \"original_text\",\n",
        "        \"å¤ç±åŸæ–‡\": \"original_text\",\n",
        "        \"Original_Text\": \"original_text\",\n",
        "\n",
        "        \"è§£é‡‹\": \"plain_explanation\",\n",
        "        \"ç™½è©±è§£é‡‹\": \"plain_explanation\",\n",
        "        \"Explanation\": \"plain_explanation\",\n",
        "\n",
        "        \"å»ºè­°\": \"actionable_advice\",\n",
        "        \"åŒ–è§£å»ºè­°\": \"actionable_advice\",\n",
        "        \"Advice\": \"actionable_advice\",\n",
        "\n",
        "        \"æ¨™ç±¤\": \"tags\",\n",
        "        \"é—œéµå­—\": \"tags\",\n",
        "        \"Tags\": \"tags\"\n",
        "    }\n",
        "\n",
        "    fixed_count = 0\n",
        "    fixed_data = []\n",
        "\n",
        "    for item in data:\n",
        "        new_item = item.copy()\n",
        "\n",
        "        # å˜—è©¦ä¿®å¾©æ¯ä¸€å€‹ Key\n",
        "        for wrong_key, correct_key in key_mapping.items():\n",
        "            if wrong_key in new_item and correct_key not in new_item:\n",
        "                new_item[correct_key] = new_item.pop(wrong_key)\n",
        "                # print(f\"   ğŸ”§ ä¿®å¾©: {wrong_key} -> {correct_key}\")\n",
        "\n",
        "        # æª¢æŸ¥æ˜¯å¦ä¿®å¾©æˆåŠŸ (æ˜¯å¦æœ‰æ¨™æº– Key)\n",
        "        if \"modern_title\" in new_item:\n",
        "            fixed_data.append(new_item)\n",
        "            fixed_count += 1\n",
        "\n",
        "    # 3. å„²å­˜ä¿®å¾©å¾Œçš„æª”æ¡ˆ\n",
        "    if fixed_count > 0:\n",
        "        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(fixed_data, f, ensure_ascii=False, indent=4)\n",
        "        print(f\"\\nâœ… æˆåŠŸä¿®å¾©ä¸¦æ¨™æº–åŒ–äº† {fixed_count} ç­†è³‡æ–™ï¼\")\n",
        "        print(\"ğŸ‘‰ ç¾åœ¨ä½ å¯ä»¥é‡æ–°åŸ·è¡Œ 'é‡å»ºè³‡æ–™åº«' çš„è…³æœ¬äº†ã€‚\")\n",
        "    else:\n",
        "        print(\"\\nâš ï¸ ç„¡æ³•è‡ªå‹•ä¿®å¾©ã€‚è«‹æª¢æŸ¥ä¸Šæ–¹å°å‡ºçš„ Keysï¼Œ8B å¯èƒ½ç”Ÿæˆäº†å®Œå…¨ä¸åŒçš„çµæ§‹ã€‚\")\n",
        "\n",
        "# åŸ·è¡Œä¿®å¾©\n",
        "fix_json_keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdfJqXOnXlA-",
        "outputId": "f53fb55e-6a0f-4c73-d66e-bc85c03abf57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ•µï¸â€â™‚ï¸ æ­£åœ¨æª¢æŸ¥ fengshui_refined_gold.json çš„å…§å®¹çµæ§‹...\n",
            "\n",
            "ğŸ“ ç¬¬ä¸€ç­†è³‡æ–™çš„ Keys :\n",
            "['modern_title', 'original_text', 'plain_explanation', 'actionable_advice', 'tags', 'source_book']\n",
            "\n",
            "âœ… æˆåŠŸä¿®å¾©ä¸¦æ¨™æº–åŒ–äº† 22 ç­†è³‡æ–™ï¼\n",
            "ğŸ‘‰ ç¾åœ¨ä½ å¯ä»¥é‡æ–°åŸ·è¡Œ 'é‡å»ºè³‡æ–™åº«' çš„è…³æœ¬äº†ã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "import time\n",
        "import gc # Garbage Collector\n",
        "import json\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "# ==========================================\n",
        "# 1. å¼·åˆ¶é‡ç½®è³‡æ–™åº« (Robust Reset)\n",
        "# ==========================================\n",
        "def force_reset_database():\n",
        "    persist_dir = \"./chroma_db\"\n",
        "\n",
        "    print(\"ğŸ§¹ é–‹å§‹æ¸…ç†èˆŠè³‡æ–™åº«...\")\n",
        "\n",
        "    # 1. å¼·åˆ¶é‡‹æ”¾è¨˜æ†¶é«”ä¸­çš„ Chroma ç‰©ä»¶\n",
        "    # é€™æ˜¯è§£æ±º 'readonly database' çš„é—œéµ\n",
        "    if 'db' in globals():\n",
        "        del globals()['db']\n",
        "    gc.collect()\n",
        "\n",
        "    # 2. åˆªé™¤è³‡æ–™å¤¾\n",
        "    if os.path.exists(persist_dir):\n",
        "        try:\n",
        "            shutil.rmtree(persist_dir)\n",
        "            print(\"   âœ… èˆŠè³‡æ–™å¤¾å·²åˆªé™¤\")\n",
        "            time.sleep(1) # ç­‰å¾…æª”æ¡ˆç³»çµ±é‡‹æ”¾é–å®š\n",
        "        except Exception as e:\n",
        "            print(f\"   âŒ åˆªé™¤å¤±æ•— (è«‹å˜—è©¦é‡å•Ÿ Runtime): {e}\")\n",
        "            return False\n",
        "\n",
        "    return True\n",
        "\n",
        "# ==========================================\n",
        "# 2. æ³¨å…¥æ‰€æœ‰é»ƒé‡‘è³‡æ–™ (Ingest)\n",
        "# ==========================================\n",
        "def ingest_all_gold_data():\n",
        "    # å…ˆåŸ·è¡Œé‡ç½®\n",
        "    if not force_reset_database():\n",
        "        return\n",
        "\n",
        "    print(\"ğŸš€ é–‹å§‹é‡å»ºé»ƒé‡‘è³‡æ–™åº«...\")\n",
        "\n",
        "    # åˆå§‹åŒ– Embedding\n",
        "    model_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
        "    all_documents = []\n",
        "\n",
        "    # --- è®€å–é¢¨æ°´è³‡æ–™ ---\n",
        "    fengshui_file = \"fengshui_refined_gold.json\"\n",
        "    if os.path.exists(fengshui_file):\n",
        "        print(f\"   ğŸ“– è®€å–é¢¨æ°´è³‡æ–™ï¼š{fengshui_file}\")\n",
        "        with open(fengshui_file, 'r', encoding='utf-8') as f:\n",
        "            fs_data = json.load(f)\n",
        "        for item in fs_data:\n",
        "            content = f\"ä¸»é¡Œï¼š{item['modern_title']}\\nå¤ç±åŸæ–‡ï¼š{item['original_text']}\\nç™½è©±è§£é‡‹ï¼š{item['plain_explanation']}\\nå°ˆå®¶å»ºè­°ï¼š{item['actionable_advice']}\\né—œéµå­—ï¼š{item['tags']}\"\n",
        "            doc = Document(\n",
        "                page_content=content,\n",
        "                metadata={\"source\": item.get('source_book', 'é€šç”¨é¢¨æ°´'), \"category\": \"fengshui\", \"type\": \"gold\"}\n",
        "            )\n",
        "            all_documents.append(doc)\n",
        "    else:\n",
        "        print(f\"   âš ï¸ æ‰¾ä¸åˆ° {fengshui_file}ï¼Œè·³éã€‚\")\n",
        "\n",
        "    # --- è®€å–æ³•è¦è³‡æ–™ ---\n",
        "    science_file = \"building_regulations_full.json\"\n",
        "    if os.path.exists(science_file):\n",
        "        print(f\"   ğŸ“– è®€å–æ³•è¦è³‡æ–™ï¼š{science_file}\")\n",
        "        with open(science_file, 'r', encoding='utf-8') as f:\n",
        "            sci_data = json.load(f)\n",
        "        for item in sci_data:\n",
        "            # é€™è£¡éœ€è¦æª¢æŸ¥ä¸€ä¸‹ json çµæ§‹çš„ key\n",
        "            # å¦‚æœä½ æ˜¯ç”¨ä¸Šé¢çˆ¬èŸ²æŠ“çš„ï¼Œkey æ‡‰è©²æ˜¯ 'ArticleNo' å’Œ 'ArticleContent'\n",
        "            # å¦‚æœæ˜¯ç”¨æ¨¡æ“¬çš„ï¼Œå¯èƒ½ä¸ä¸€æ¨£ï¼Œé€™è£¡åšå€‹é˜²å‘†\n",
        "            art_no = item.get('ArticleNo') or item.get('id')\n",
        "            art_content = item.get('ArticleContent') or item.get('content')\n",
        "\n",
        "            if art_no and art_content:\n",
        "                text = f\"{art_no}ï¼š{art_content}\"\n",
        "                doc = Document(\n",
        "                    page_content=text,\n",
        "                    metadata={\"source\": \"å»ºç¯‰æŠ€è¡“è¦å‰‡\", \"category\": \"science\", \"article_id\": art_no}\n",
        "                )\n",
        "                all_documents.append(doc)\n",
        "    else:\n",
        "        print(f\"   âš ï¸ æ‰¾ä¸åˆ° {science_file}ï¼Œè·³éã€‚\")\n",
        "\n",
        "    # --- å¯«å…¥ ChromaDB ---\n",
        "    if all_documents:\n",
        "        print(f\"   ğŸ’¾ æ­£åœ¨å¯«å…¥ {len(all_documents)} ç­†è³‡æ–™åˆ° ChromaDB...\")\n",
        "        try:\n",
        "            db = Chroma.from_documents(\n",
        "                documents=all_documents,\n",
        "                embedding=embeddings,\n",
        "                persist_directory=\"./chroma_db\"\n",
        "            )\n",
        "            print(\"ğŸ‰ è³‡æ–™åº«é‡å»ºå®Œæˆï¼\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ å¯«å…¥å¤±æ•—: {e}\")\n",
        "            print(\"ğŸ‘‰ å»ºè­°ï¼šè«‹é»æ“Šä¸Šæ–¹é¸å–® 'Runtime' -> 'Restart session' å¾Œå†è©¦ä¸€æ¬¡ã€‚\")\n",
        "    else:\n",
        "        print(\"âŒ æ²’æœ‰ä»»ä½•è³‡æ–™è¢«å¯«å…¥ã€‚\")\n",
        "\n",
        "# åŸ·è¡Œ\n",
        "ingest_all_gold_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtMRhfq3X4rX",
        "outputId": "fc28fc73-1783-4e39-e214-be5827d836ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§¹ é–‹å§‹æ¸…ç†èˆŠè³‡æ–™åº«...\n",
            "ğŸš€ é–‹å§‹é‡å»ºé»ƒé‡‘è³‡æ–™åº«...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ğŸ“– è®€å–é¢¨æ°´è³‡æ–™ï¼šfengshui_refined_gold.json\n",
            "   ğŸ“– è®€å–æ³•è¦è³‡æ–™ï¼šbuilding_regulations_full.json\n",
            "   ğŸ’¾ æ­£åœ¨å¯«å…¥ 411 ç­†è³‡æ–™åˆ° ChromaDB...\n",
            "ğŸ‰ è³‡æ–™åº«é‡å»ºå®Œæˆï¼\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 4. ä¸»è¦ç¨‹å¼"
      ],
      "metadata": {
        "id": "TuyFtPcND2Yz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## requirements.txt"
      ],
      "metadata": {
        "id": "JKpgftyJ_nfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\n",
        "streamlit\n",
        "langchain-chroma\n",
        "langchain-huggingface\n",
        "langchain-community\n",
        "langchain-core\n",
        "langchain-google-genai\n",
        "langchain-groq\n",
        "langchain-openai\n",
        "huggingface-hub\n",
        "sentence-transformers\n",
        "chromadb\n",
        "tenacity\n",
        "pydantic\n",
        "google-api-core\n",
        "google-generativeai\n",
        "google-cloud-core\n",
        "pysqlite3-binary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NAhzhhR_ini",
        "outputId": "70c4d19a-a4e9-46b4-8fb2-82653e240cef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## styles.py"
      ],
      "metadata": {
        "id": "aUgsTTJn-lVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile styles.py\n",
        "import streamlit as st\n",
        "\n",
        "def apply_floating_bubble_style():\n",
        "    st.markdown(\"\"\"\n",
        "    <style>\n",
        "        /* å…¨å±€èƒŒæ™¯ï¼šæ·±è‰²æ¼¸å±¤ï¼Œç‡Ÿé€ ç¥ç¥•ç§‘æŠ€æ„Ÿ */\n",
        "        .stApp {\n",
        "            background: linear-gradient(135deg, #0f0c29, #302b63, #24243e);\n",
        "            color: #E0E0E0;\n",
        "            font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif;\n",
        "        }\n",
        "\n",
        "        /* éš±è— Streamlit é è¨­çš„ Header å’Œ Footer ä»¥æ±‚ç¾è§€ */\n",
        "        header {visibility: hidden;}\n",
        "        footer {visibility: hidden;}\n",
        "\n",
        "        /* å®šç¾©æ¼‚æµ®å‹•ç•« */\n",
        "        @keyframes float {\n",
        "            0% { transform: translateY(0px); }\n",
        "            50% { transform: translateY(-10px); }\n",
        "            100% { transform: translateY(0px); }\n",
        "        }\n",
        "\n",
        "        /* æ¨™é¡Œæ¨£å¼ */\n",
        "        .main-title {\n",
        "            font-size: 3em;\n",
        "            font-weight: 700;\n",
        "            background: -webkit-linear-gradient(#00c6ff, #0072ff);\n",
        "            -webkit-background-clip: text;\n",
        "            -webkit-text-fill-color: transparent;\n",
        "            text-align: center;\n",
        "            margin-bottom: 30px;\n",
        "            text-shadow: 0 0 20px rgba(0, 198, 255, 0.3);\n",
        "        }\n",
        "\n",
        "        /* é€šç”¨æ°£æ³¡å¡ç‰‡ (Glassmorphism) */\n",
        "        .bubble-card {\n",
        "            background: rgba(255, 255, 255, 0.05); /* æ¥µæ·¡çš„ç™½è‰² */\n",
        "            backdrop-filter: blur(12px);           /* æ¯›ç»ç’ƒæ¨¡ç³Š */\n",
        "            -webkit-backdrop-filter: blur(12px);\n",
        "            border-radius: 20px;\n",
        "            border: 1px solid rgba(255, 255, 255, 0.1);\n",
        "            padding: 20px;\n",
        "            margin-bottom: 20px;\n",
        "            box-shadow: 0 8px 32px 0 rgba(0, 0, 0, 0.37);\n",
        "            color: #ffffff;\n",
        "            transition: all 0.3s ease;\n",
        "        }\n",
        "\n",
        "        /* æ»‘é¼ æ‡¸åœæ™‚çš„æ•ˆæœ */\n",
        "        .bubble-card:hover {\n",
        "            background: rgba(255, 255, 255, 0.1);\n",
        "            box-shadow: 0 8px 32px 0 rgba(0, 0, 0, 0.5);\n",
        "            transform: scale(1.02);\n",
        "        }\n",
        "\n",
        "        /* å·¦å´ï¼šç§‘å­¸è—è‰²æ°£æ³¡ */\n",
        "        .sci-bubble {\n",
        "            border-left: 5px solid #00B4D8;\n",
        "            animation: float 6s ease-in-out infinite;\n",
        "        }\n",
        "        .sci-title {\n",
        "            color: #00B4D8;\n",
        "            font-weight: bold;\n",
        "            font-size: 1.2em;\n",
        "            margin-bottom: 10px;\n",
        "            display: flex;\n",
        "            align-items: center;\n",
        "        }\n",
        "\n",
        "        /* å³å´ï¼šé¢¨æ°´é‡‘è‰²æ°£æ³¡ */\n",
        "        .fs-bubble {\n",
        "            border-left: 5px solid #FFD700;\n",
        "            animation: float 6s ease-in-out infinite;\n",
        "            animation-delay: 1s; /* éŒ¯é–‹å‹•ç•«æ™‚é–“ */\n",
        "        }\n",
        "        .fs-title {\n",
        "            color: #FFD700;\n",
        "            font-weight: bold;\n",
        "            font-size: 1.2em;\n",
        "            margin-bottom: 10px;\n",
        "            display: flex;\n",
        "            align-items: center;\n",
        "        }\n",
        "\n",
        "        /* åº•éƒ¨ï¼šæ•´åˆå»ºè­°ç´«è‰²æ°£æ³¡ */\n",
        "        .mediator-bubble {\n",
        "            background: rgba(108, 92, 231, 0.1);\n",
        "            border: 1px solid rgba(108, 92, 231, 0.3);\n",
        "            border-radius: 25px;\n",
        "            padding: 30px;\n",
        "            margin-top: 20px;\n",
        "        }\n",
        "        .mediator-title {\n",
        "            color: #a29bfe;\n",
        "            font-size: 1.5em;\n",
        "            text-align: center;\n",
        "            margin-bottom: 15px;\n",
        "        }\n",
        "\n",
        "        /* æŒ‰éˆ•ç¾åŒ– */\n",
        "        div.stButton > button {\n",
        "            background: linear-gradient(90deg, #00c6ff 0%, #0072ff 100%);\n",
        "            color: white;\n",
        "            border: none;\n",
        "            border-radius: 50px;\n",
        "            padding: 10px 24px;\n",
        "            font-weight: bold;\n",
        "            transition: 0.3s;\n",
        "            box-shadow: 0 0 15px rgba(0, 114, 255, 0.5);\n",
        "        }\n",
        "        div.stButton > button:hover {\n",
        "            transform: translateY(-2px);\n",
        "            box-shadow: 0 0 25px rgba(0, 114, 255, 0.8);\n",
        "        }\n",
        "\n",
        "    </style>\n",
        "    \"\"\", unsafe_allow_html=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0TZMYmgDRKb",
        "outputId": "f201127c-a297-4792-b999-38ea0f0a82f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting styles.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## logic.py"
      ],
      "metadata": {
        "id": "uDaNjrNp0T3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile logic.py\n",
        "import os\n",
        "import base64\n",
        "import urllib.parse\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
        "from pydantic import BaseModel, Field\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\n",
        "from google.api_core.exceptions import ResourceExhausted\n",
        "\n",
        "# å¼•å…¥å„å¤§æ¨¡å‹åº«\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# ===========================\n",
        "# 1. çŸ¥è­˜åº«\n",
        "# ===========================\n",
        "class KnowledgeBase:\n",
        "    def __init__(self, persist_dir=\"./chroma_db\"):\n",
        "        self.persist_dir = persist_dir\n",
        "        self.embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
        "        self.vector_db = None\n",
        "\n",
        "    def load_db(self):\n",
        "        if os.path.exists(self.persist_dir) and os.path.isdir(self.persist_dir):\n",
        "            try:\n",
        "                self.vector_db = Chroma(persist_directory=self.persist_dir, embedding_function=self.embeddings)\n",
        "                return True\n",
        "            except Exception as e:\n",
        "                print(f\"âŒ è³‡æ–™åº«è¼‰å…¥å¤±æ•—: {e}\")\n",
        "                return False\n",
        "        else:\n",
        "            print(f\"âš ï¸ è­¦å‘Šï¼šæ‰¾ä¸åˆ°è·¯å¾‘ {self.persist_dir}ï¼Œè«‹å…ˆåŸ·è¡Œè³‡æ–™é‡å»ºè…³æœ¬ï¼\")\n",
        "            return False\n",
        "\n",
        "    def get_context(self):\n",
        "        if not self.vector_db:\n",
        "            success = self.load_db()\n",
        "            if not success: return None\n",
        "        return self.vector_db.as_retriever(\n",
        "            search_type=\"mmr\",\n",
        "            search_kwargs={\"k\": 4, \"fetch_k\": 20}\n",
        "        )\n",
        "\n",
        "# ===========================\n",
        "# 2. å®šç¾©è¼¸å‡ºçµæ§‹\n",
        "# ===========================\n",
        "class MediatorOutput(BaseModel):\n",
        "    verdict: str = Field(description=\"å”èª¿è€…çš„æœ€çµ‚æŠ˜è¡·æ–¹æ¡ˆèˆ‡å»ºè­°ï¼Œç´”æ–‡å­—\")\n",
        "    design_prompt: str = Field(description=\"çµ¦ AI ç¹ªåœ–æ¨¡å‹çš„è‹±æ–‡ Prompt\")\n",
        "\n",
        "# ===========================\n",
        "# 3. å¤šä»£ç†äººæ ¸å¿ƒé‚è¼¯\n",
        "# ===========================\n",
        "class LogicCore:\n",
        "    def __init__(self):\n",
        "        self.kb = KnowledgeBase()\n",
        "        self.kb.load_db()\n",
        "\n",
        "    # --- ğŸ­ LLM å·¥å»  ---\n",
        "    def _create_llm(self, provider, api_key, model_name=None):\n",
        "        if not api_key:\n",
        "            raise ValueError(f\"è«‹è¼¸å…¥ {provider} çš„ API Key\")\n",
        "\n",
        "        if provider == \"Groq\":\n",
        "            return ChatGroq(\n",
        "                groq_api_key=api_key,\n",
        "                model_name=model_name or \"llama-3.3-70b-versatile\",\n",
        "                temperature=0.5\n",
        "            )\n",
        "        elif provider == \"OpenAI\":\n",
        "            return ChatOpenAI(\n",
        "                api_key=api_key,\n",
        "                model=model_name or \"gpt-4o\",\n",
        "                temperature=0.5\n",
        "            )\n",
        "        elif provider == \"Gemini\":\n",
        "            return ChatGoogleGenerativeAI(\n",
        "                google_api_key=api_key,\n",
        "                model=model_name or \"gemini-2.5-flash\",\n",
        "                temperature=0.5\n",
        "            )\n",
        "        else:\n",
        "            raise ValueError(\"ä¸æ”¯æ´çš„æ¨¡å‹ä¾›æ‡‰å•†\")\n",
        "\n",
        "    # --- ğŸ“š å…±ç”¨åŠŸèƒ½ï¼šRAG æª¢ç´¢ ---\n",
        "    def get_rag_context(self, query):\n",
        "        retriever = self.kb.get_context()\n",
        "        docs = retriever.invoke(query) if retriever else []\n",
        "        context_text = \"\\n\".join([d.page_content for d in docs])\n",
        "        return context_text\n",
        "\n",
        "    # --- ğŸ‘ï¸ è¦–è¦ºä»£ç†äºº ---\n",
        "    def analyze_image(self, image_bytes, api_key, mime_type=\"image/jpeg\"):\n",
        "        if not api_key: return \"æœªæä¾› Gemini Keyï¼Œç„¡æ³•åˆ†æåœ–ç‰‡ã€‚\"\n",
        "\n",
        "        vision_model = ChatGoogleGenerativeAI(\n",
        "            model=\"gemini-3.0-pro\",\n",
        "            temperature=0.7,\n",
        "            google_api_key=api_key\n",
        "        )\n",
        "        b64_string = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
        "        image_url = f\"data:{mime_type};base64,{b64_string}\"\n",
        "\n",
        "        prompt = \"è«‹ä»”ç´°è§€å¯Ÿé€™å¼µå®¤å…§è¨­è¨ˆåœ–ç‰‡ã€‚æè¿°ç©ºé–“ä½ˆå±€ï¼Œé‡é»åŒ…å«ï¼šçª—æˆ¶ä½ç½®ã€æ¨‘æŸ±ä½ç½®ã€é–€çš„ç›¸å°ä½ç½®ã€‚è«‹ç”¨å®¢è§€çš„ç´”æ–‡å­—æè¿°ã€‚\"\n",
        "        message = [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": prompt},\n",
        "                    {\"type\": \"image_url\", \"image_url\": image_url}\n",
        "                ]\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        response = vision_model.invoke(message)\n",
        "        return response.content\n",
        "\n",
        "    # --- ğŸ—ï¸ Agent 1: å»ºç¯‰ç§‘å­¸å®¶ ---\n",
        "    def run_architect_agent(self, context, query, provider, api_key, model_name):\n",
        "        llm = self._create_llm(provider, api_key, model_name)\n",
        "\n",
        "        template = \"\"\"ä½ ç¾åœ¨æ˜¯ã€å°ˆæ¥­çš„å»ºç¯‰ç§‘å­¸ç ”ç©¶å“¡ã€‘ã€‚è«‹æ ¹æ“šã€åƒè€ƒè³‡æ–™ã€‘èˆ‡ã€ä½¿ç”¨è€…éœ€æ±‚ã€‘ï¼Œé€²è¡Œç§‘å­¸æ€§çš„ç©ºé–“æª¢è¨ã€‚\n",
        "\n",
        "        ã€åƒè€ƒè³‡æ–™ã€‘ï¼š{context}\n",
        "        ã€ä½¿ç”¨è€…éœ€æ±‚ã€‘ï¼š{query}\n",
        "\n",
        "        è«‹åŸ·è¡Œä»¥ä¸‹æ€è€ƒæ­¥é©Ÿï¼š\n",
        "        1. **è¨­è¨ˆæ„åœ–åˆ†æ**ï¼šç†è§£ä½¿ç”¨è€…æƒ³åšä»€éº¼ã€‚\n",
        "        2. **ç§‘å­¸æ€§çš„åˆ¤æ–·**ï¼š\n",
        "           - æ€è€ƒæ”¹å‹•å°ç©ºé–“é€ æˆçš„ç‰©ç†çµæœï¼ˆæ²¹ç…™ã€æ¿•æ°£ã€é€šé¢¨ï¼‰ã€‚\n",
        "           - æª¢æŸ¥ã€åƒè€ƒè³‡æ–™ã€‘ï¼Œåƒ…å¼•ç”¨ã€Œç›´æ¥ç›¸é—œã€æ¢æ–‡ã€‚\n",
        "           - âš ï¸ é‡è¦ï¼šè‹¥åƒè€ƒè³‡æ–™ç„¡é—œï¼Œè«‹å¿½ç•¥ä¸¦ä»¥ç§‘å­¸å¸¸è­˜å›ç­”ã€‚\n",
        "\n",
        "        3. **è¼¸å‡ºè¦æ±‚**ï¼šè«‹è¼¸å‡º HTML æ ¼å¼ï¼ŒåŒ…å«ï¼š\n",
        "           - `<p><b>ğŸ“ è¨­è¨ˆæ„åœ–ï¼š</b>...</p>`\n",
        "           - `<p><b>ğŸ” ç§‘å­¸æª¢è¦–èˆ‡æ³•è¦ï¼š</b>...</p>`\n",
        "           - `<ul><li><b>å¼•ç”¨ä¾æ“šï¼š</b>(ç›´æ¥å¯«å‡ºç›¸é—œæ³•æ¢ï¼Œè‹¥ç„¡RAGè³‡æ–™å‰‡å¯«\"ä¾æ“šä¸€èˆ¬å»ºç¯‰å¸¸è¦\")</li><li><b>å…·é«”å»ºè­°ï¼š</b>...</li></ul>`\n",
        "        \"\"\"\n",
        "\n",
        "        prompt = ChatPromptTemplate.from_template(template)\n",
        "        chain = prompt | llm | StrOutputParser()\n",
        "        return chain.invoke({\"context\": context, \"query\": query})\n",
        "\n",
        "    # --- ğŸ”® Agent 2: é¢¨æ°´å¤§å¸« ---\n",
        "    def run_fengshui_agent(self, context, query, provider, api_key, model_name):\n",
        "        llm = self._create_llm(provider, api_key, model_name)\n",
        "\n",
        "        template = \"\"\"ä½ ç¾åœ¨æ˜¯ã€è³‡æ·±é¢¨æ°´å¤§å¸«ã€‘ã€‚è«‹æ ¹æ“šã€åƒè€ƒè³‡æ–™ã€‘èˆ‡ã€ä½¿ç”¨è€…éœ€æ±‚ã€‘ï¼Œé€²è¡Œæ ¼å±€å‰å‡¶è¨ºæ–·ã€‚\n",
        "\n",
        "        ã€åƒè€ƒè³‡æ–™ã€‘ï¼š{context}\n",
        "        ã€ä½¿ç”¨è€…éœ€æ±‚ã€‘ï¼š{query}\n",
        "\n",
        "        è«‹åŸ·è¡Œä»¥ä¸‹æ€è€ƒæ­¥é©Ÿï¼š\n",
        "        1. **ç…æ°£è¨ºæ–·**ï¼šåˆ¤æ–·æ ¼å±€æ¶‰åŠå“ªç¨®å…·é«”ç¦å¿Œã€‚\n",
        "        2. **å¤ç±æ¯”å°**ï¼š\n",
        "           - æª¢æŸ¥ã€åƒè€ƒè³‡æ–™ã€‘æ˜¯å¦æœ‰å°æ‡‰åŸæ–‡ã€‚\n",
        "           - âš ï¸ é‡è¦ï¼šè‹¥åƒè€ƒè³‡æ–™ç„¡é—œï¼Œè«‹å¿½ç•¥ä¸¦ä»¥å…§å»ºé¢¨æ°´çŸ¥è­˜å›ç­”ã€‚\n",
        "\n",
        "        3. **è¼¸å‡ºè¦æ±‚**ï¼šè«‹è¼¸å‡º HTML æ ¼å¼ï¼ŒåŒ…å«ï¼š\n",
        "           - `<p><b>ğŸ”® é™½å®…æ ¼å±€è¨ºæ–·ï¼š</b>...</p>`\n",
        "           - `<p><b>ğŸ“œ å¤ç±èˆ‡æ°‘ä¿—è§€é»ï¼š</b>...</p>`\n",
        "           - `<ul><li><b>ç¶“å…¸å¼•æ“šï¼š</b>(ç›´æ¥å¯«å‡ºç¶“å…¸åç¨±ï¼Œè‹¥ç„¡RAGè³‡æ–™å‰‡å¯«ä¾æ“šä¸€èˆ¬é¢¨æ°´è¦‹è§£)...</li><li><b>åŒ–è§£ä¹‹é“ï¼š</b>...</li></ul>`\n",
        "        \"\"\"\n",
        "\n",
        "        prompt = ChatPromptTemplate.from_template(template)\n",
        "        chain = prompt | llm | StrOutputParser()\n",
        "        return chain.invoke({\"context\": context, \"query\": query})\n",
        "\n",
        "    # --- ğŸ¤ Agent 3: å”èª¿è¨­è¨ˆå¸« ---\n",
        "    def run_mediator_agent(self, arch_res, fs_res, query, style, provider, api_key, model_name):\n",
        "        llm = self._create_llm(provider, api_key, model_name)\n",
        "        parser = JsonOutputParser(pydantic_object=MediatorOutput)\n",
        "\n",
        "        template = \"\"\"ä½ æ˜¯ä¸€å€‹å¤šå·¥è™•ç†çš„å°ˆå®¶ï¼Œç¾åœ¨åŒæ™‚æ“”ä»»ã€å®¶åº­è£ä¿®å”èª¿è€…ã€‘èˆ‡ã€AI ç¹ªåœ–è© å”±å¸«ã€‘ã€‚\n",
        "\n",
        "        ã€ä½¿ç”¨è€…éœ€æ±‚ã€‘ï¼š{query}\n",
        "        ã€é¢¨æ ¼åå¥½ã€‘ï¼š{style}\n",
        "\n",
        "        ã€å»ºç¯‰å¸«æ„è¦‹ã€‘ï¼š{arch_res}\n",
        "        ã€é¢¨æ°´å¸«æ„è¦‹ã€‘ï¼š{fs_res}\n",
        "\n",
        "        è«‹å®Œæˆä»¥ä¸‹å…©é …ä»»å‹™ä¸¦è¼¸å‡º JSONï¼š\n",
        "\n",
        "        ### ä»»å‹™ 1ï¼šå”èª¿èˆ‡æŠ˜è¡· (Verdict)\n",
        "        1. ç¶œåˆä¸Šè¿°å…©ä½çš„è§€é»ï¼ŒæŒ‡å‡ºè¡çªé»ï¼Œæˆ–æ˜¯çµ„åˆé›™æ–¹æå‡ºçš„å…±è­˜ã€‚\n",
        "        2. æä¾›ä¸€å€‹ã€Œå…·é«”æŠ˜è¡·æ–¹æ¡ˆã€ï¼ŒåŒæ™‚æ»¿è¶³ç§‘å­¸ï¼ˆé€šé¢¨/æ¡å…‰ï¼‰èˆ‡é¢¨æ°´ï¼ˆå¿ƒç†/é¿ç…ï¼‰ã€‚\n",
        "        3. è¼¸å‡ºç´”æ–‡å­—ï¼Œèªæ°£æº«å’Œå°ˆæ¥­ã€‚\n",
        "\n",
        "        ### ä»»å‹™ 2ï¼šè¦–è¦ºåŒ– Prompt ç”Ÿæˆ (Design Prompt)\n",
        "        æ ¹æ“šä½ çš„æŠ˜è¡·æ–¹æ¡ˆèˆ‡ä½¿ç”¨è€…çš„ã€Œ{style}ã€é¢¨æ ¼ï¼Œæ’°å¯«ä¸€å€‹è‹±æ–‡ Promptã€‚\n",
        "        **é—œéµè¦æ±‚ï¼š**\n",
        "        - **é‡å° FLUX æ¨¡å‹å„ªåŒ–**\n",
        "        - **è¦–è§’è¨­å®š**ï¼šä½¿ç”¨ \"High-angle 3/4 perspective view\" åŠ \"Cutaway 3D render\"ã€‚\n",
        "        - **æ§‹åœ–ç›®æ¨™**ï¼šç•«é¢ç¨å¾®æ—‹è½‰ï¼Œä¸è¦å®Œå…¨æ­£å°ç‰†é¢ã€‚\n",
        "        - åŒ…å«é¢¨æ ¼é—œéµå­— (e.g., photorealistic, 8k)ã€‚\n",
        "        - é¿å…ä¸ç¬¦åˆç¾å¯¦çš„æ™¯è±¡ã€‚\n",
        "\n",
        "        {format_instructions}\n",
        "        \"\"\"\n",
        "\n",
        "        prompt = ChatPromptTemplate.from_template(template, partial_variables={\"format_instructions\": parser.get_format_instructions()})\n",
        "        chain = prompt | llm | parser\n",
        "        return chain.invoke({\"arch_res\": arch_res, \"fs_res\": fs_res, \"query\": query, \"style\": style})\n",
        "\n",
        "    # --- ğŸ¨ ç¹ªåœ–å·¥å…· ---\n",
        "    def generate_image_via_pollinations(self, prompt):\n",
        "        \"\"\"\n",
        "        ä½¿ç”¨ Pollinations.ai å…è²»ç”Ÿæˆåœ–ç‰‡\n",
        "        \"\"\"\n",
        "        import urllib.parse\n",
        "        import random  # æ–°å¢ random ä»¥ç”Ÿæˆéš¨æ©Ÿç¨®å­\n",
        "\n",
        "        try:\n",
        "            # 1. å° Prompt é€²è¡Œ URL ç·¨ç¢¼ï¼Œé¿å…ç‰¹æ®Šå­—ç¬¦å°è‡´é€£çµå¤±æ•ˆ\n",
        "            encoded_prompt = urllib.parse.quote(prompt)\n",
        "\n",
        "            # 2. ç”Ÿæˆéš¨æ©Ÿç¨®å­ (Seed)ï¼Œç¢ºä¿æ¯æ¬¡ç”Ÿæˆçš„æ§‹åœ–éƒ½ä¸ä¸€æ¨£\n",
        "            seed = random.randint(0, 99999)\n",
        "\n",
        "            # 3. å»ºç«‹ URL\n",
        "            # model=flux-realism: æŒ‡å®š 2025 æ›´å¼·çš„çœŸå¯¦æ„Ÿæ¨¡å‹\n",
        "            # seed={seed}: å›ºå®šéš¨æ©Ÿæ€§\n",
        "            # nologo=true: å˜—è©¦éš±è—æµ®æ°´å°\n",
        "            url = f\"https://image.pollinations.ai/prompt/{encoded_prompt}?model=flux-realism&width=1024&height=768&seed={seed}&nologo=true\"\n",
        "\n",
        "            return url\n",
        "        except Exception as e:\n",
        "            print(f\"Pollinations Error: {e}\")\n",
        "            return None\n",
        "\n",
        "    def generate_image_from_hf(self, prompt, hf_token):\n",
        "        if not hf_token: return None\n",
        "        from huggingface_hub import InferenceClient\n",
        "        client = InferenceClient(model=\"black-forest-labs/FLUX.1-schnell\", token=hf_token)\n",
        "        try:\n",
        "            image = client.text_to_image(prompt)\n",
        "            return image\n",
        "        except Exception as e:\n",
        "            print(f\"HF Error: {e}\")\n",
        "            return None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AzvUekDy0Qx",
        "outputId": "5db35458-1c1e-46e4-eee8-89ead5284bb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting logic.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## app.py"
      ],
      "metadata": {
        "id": "E6P0fwU70fO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import sys\n",
        "import os\n",
        "\n",
        "try:\n",
        "    __import__('pysqlite3')\n",
        "    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "import streamlit as st\n",
        "import styles\n",
        "from logic import LogicCore\n",
        "import time\n",
        "\n",
        "st.set_page_config(\n",
        "    page_title=\"HarmonyChainSpace\",\n",
        "    layout=\"wide\",\n",
        "    page_icon=\"â˜¯ï¸\"\n",
        ")\n",
        "styles.apply_floating_bubble_style()\n",
        "\n",
        "# åˆå§‹åŒ–æ ¸å¿ƒ\n",
        "if \"core\" not in st.session_state:\n",
        "    st.session_state.core = LogicCore()\n",
        "\n",
        "core = st.session_state.core\n",
        "\n",
        "# åˆå§‹åŒ– Session State\n",
        "if \"arch_result\" not in st.session_state: st.session_state.arch_result = None\n",
        "if \"fs_result\" not in st.session_state: st.session_state.fs_result = None\n",
        "if \"mediator_result\" not in st.session_state: st.session_state.mediator_result = None\n",
        "if \"last_request\" not in st.session_state: st.session_state.last_request = 0\n",
        "if \"prompt_content\" not in st.session_state: st.session_state.prompt_content = \"\"\n",
        "\n",
        "\n",
        "st.markdown('<div class=\"main-title\">â˜¯ï¸ HarmonyChainSpace Â· é›™è»Œç³»çµ± </div>', unsafe_allow_html=True)\n",
        "\n",
        "# ==========================================\n",
        "# ğŸ›ï¸ å´é‚Šæ¬„ï¼šè¨­å®šèˆ‡ API Key\n",
        "# ==========================================\n",
        "with st.sidebar:\n",
        "    st.header(\"ğŸ”‘ æ¨¡å‹èˆ‡å·¥å…·è¨­å®š\")\n",
        "\n",
        "    # 1. é¸æ“‡ä¾›æ‡‰å•†\n",
        "    provider = st.selectbox(\"1. é¸æ“‡æ¨ç†å¤§è…¦\", [\"Groq\", \"OpenAI\", \"Gemini\"])\n",
        "\n",
        "    # 2. æ ¹æ“šé¸æ“‡é¡¯ç¤ºå°æ‡‰çš„ Key è¼¸å…¥æ¡†èˆ‡ 2025 æœ€æ–°æ¨¡å‹\n",
        "    api_key = \"\"\n",
        "    model_name = \"\"\n",
        "\n",
        "    if provider == \"Groq\":\n",
        "        api_key = st.text_input(\"Groq API Key\", type=\"password\", help=\"æ¨è–¦ Llama 3.3\")\n",
        "        model_name = st.selectbox(\"æ¨¡å‹ç‰ˆæœ¬\", [\"llama-3.3-70b-versatile\", \"llama-3.1-8b-instant\"])\n",
        "\n",
        "    elif provider == \"OpenAI\":\n",
        "        api_key = st.text_input(\"OpenAI API Key\", type=\"password\", help=\"æ¨è–¦ GPT-4o\")\n",
        "        model_name = st.selectbox(\"æ¨¡å‹ç‰ˆæœ¬\", [\"gpt-4o\", \"gpt-4o-mini\"])\n",
        "\n",
        "    elif provider == \"Gemini\":\n",
        "        api_key = st.text_input(\"Google AI Studio Key\", type=\"password\", help=\"æ¨è–¦ Gemini 2.5 Flash\")\n",
        "        model_name = st.selectbox(\"æ¨¡å‹ç‰ˆæœ¬\", [\"gemini-2.5-flash\", \"gemini-1.5-pro\"])\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    # 3. è¦–è¦ºèˆ‡ç¹ªåœ–è¨­å®š\n",
        "    st.caption(\"ğŸ¨ è¦–è¦ºèˆ‡ç¹ªåœ–å·¥å…·\")\n",
        "\n",
        "    gemini_vision_key = st.text_input(\"Gemini Vision Key (é¸å¡«)\", type=\"password\", help=\"è‹¥éœ€åˆ†æåœ–ç‰‡ï¼Œè«‹å¡«å…¥ Google Keyã€‚è‹¥ä¸Šæ–¹å·²é¸ Gemini å‰‡å¯ç•™ç©ºã€‚\")\n",
        "    if provider == \"Gemini\" and api_key and not gemini_vision_key:\n",
        "        gemini_vision_key = api_key\n",
        "\n",
        "    paint_mode = st.radio(\n",
        "        \"ç¹ªåœ–å¼•æ“\",\n",
        "        [\"Pollinations (å…è²»/ç„¡é™)\", \"Hugging Face (éœ€Token)\", \"é—œé–‰ç¹ªåœ–\"],\n",
        "        help=\"Pollinations ä½¿ç”¨ Flux æ¨¡å‹ä¸”å®Œå…¨å…è²»\"\n",
        "    )\n",
        "\n",
        "    hf_token = \"\"\n",
        "    if paint_mode == \"Hugging Face (éœ€Token)\":\n",
        "        hf_token = st.text_input(\"Hugging Face Token\", type=\"password\")\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    if st.button(\"ğŸ”„ é‡ç½®ç³»çµ±ç‹€æ…‹\"):\n",
        "        for key in [\"arch_result\", \"fs_result\", \"mediator_result\", \"prompt_content\"]:\n",
        "            if key in st.session_state: del st.session_state[key]\n",
        "        st.rerun()\n",
        "\n",
        "    uploaded_file = st.file_uploader(\"ä¸Šå‚³ç©ºé–“å¯¦æ™¯\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
        "    image_desc = \"\"\n",
        "    if uploaded_file:\n",
        "        st.image(uploaded_file, caption=\"åŸå§‹ç©ºé–“\", use_container_width=True)\n",
        "        if st.button(\"ğŸ‘ï¸ åˆ†æåœ–ç‰‡\"):\n",
        "            if not gemini_vision_key:\n",
        "                st.error(\"âŒ è«‹è¼¸å…¥ Gemini Vision Key æ‰èƒ½é€²è¡Œè¦–è¦ºåˆ†æ\")\n",
        "            else:\n",
        "                with st.spinner(\"Gemini 3.0 Pro æ­£åœ¨è§€å¯Ÿåœ–ç‰‡ç´°ç¯€...\"):\n",
        "                    image_bytes = uploaded_file.getvalue()\n",
        "                    image_desc = core.analyze_image(image_bytes, gemini_vision_key, uploaded_file.type)\n",
        "                    st.success(\"è¦–è¦ºåˆ†æå®Œæˆ\")\n",
        "                    with st.expander(\"ç­†è¨˜\"): st.write(image_desc)\n",
        "\n",
        "    with st.expander(\"ğŸ’¡ éˆæ„Ÿåœ–æ›¸é¤¨ (é»æ“Šè‡ªå‹•å¸¶å…¥)\"):\n",
        "        st.caption(\"é»æ“Šä¸‹æ–¹æŒ‰éˆ•ï¼Œè‡ªå‹•å¡«å¯«ç¶“å…¸çš„ã€Œç§‘å­¸ vs é¢¨æ°´ã€è¡çªå ´æ™¯ï¼š\")\n",
        "        scenarios = {\n",
        "            \"ğŸ“ æ¨“æ¢¯æ³•è¦é™·é˜±\\n\\n(æ¸¬è©¦ç¬¬33/36æ¢)\": \"æˆ‘æƒ³åœ¨å®¢å»³åšä¸€å€‹æ—‹è½‰æ¨“æ¢¯ï¼Œç‚ºäº†çœç©ºé–“ï¼Œæ¨“æ¢¯å¯¬åº¦åªæƒ³åš 70 å…¬åˆ†ã€‚å¦å¤–ç‚ºäº†æ¥µç°¡ç¾æ„Ÿï¼Œæˆ‘ä¸æ‰“ç®—è£æ‰¶æ‰‹ï¼Œæˆ–è€…åªè£ 50 å…¬åˆ†é«˜çš„éš±å½¢ç»ç’ƒæ‰¶æ‰‹ã€‚é€™æ¨£è¨­è¨ˆåˆæ³•å—ï¼Ÿ\",\n",
        "            \"ğŸ”¥ æ°´ç«ä¸å®¹æ¥µé™\\n\\n(æ¸¬è©¦é™½å®…ä¸‰è¦)\": \"å»šæˆ¿ç©ºé–“å¾ˆå°ï¼Œæˆ‘æ‰“ç®—æŠŠç“¦æ–¯çˆç›´æ¥ç·Šè²¼è‘—æ°´æ§½ï¼ˆè·é›¢ 0 å…¬åˆ†ï¼‰ï¼Œè€Œä¸”ç“¦æ–¯çˆçš„æ­£å°é¢å‰›å¥½å°±æ˜¯å†°ç®±ã€‚è½èªªé€™åœ¨é¢¨æ°´ä¸Šå«ã€æ°´ç«ä¸å®¹ã€ï¼ŒçœŸçš„å¾ˆåš´é‡å—ï¼Ÿ\",\n",
        "            \"ğŸš½ ä¸­å®®é€ å»\\n\\n(æ¸¬è©¦ç¬¬46æ¢/é™½å®…åæ›¸)\": \"é€™æ˜¯ä¸€é–“è€é€å¤©ï¼Œå”¯ä¸€çš„å»æ‰€å‰›å¥½åœ¨æˆ¿å­çš„ã€æ­£ä¸­å¤®ã€ï¼Œè€Œä¸”å®Œå…¨æ²’æœ‰å°å¤–çª—ã€‚æˆ‘æƒ³æŠŠå®ƒæ“´å»ºæˆè±ªè¯æµ´å®¤ï¼Œå¦‚æœä¸ç§»ä½ï¼Œåªè£ä¸€å€‹å°æŠ½é¢¨æ©Ÿç¬¦åˆæ³•è¦å—ï¼Ÿé¢¨æ°´ä¸Šæœƒæœ‰ä»€éº¼å¥åº·å½±éŸ¿ï¼Ÿ\",\n",
        "            \"ğŸ  ç©¿å ‚ç…èˆ‡æ¡å…‰\\n\\n(æ¸¬è©¦é™½å®…åæ›¸)\": \"ç‚ºäº†è®“å®¢å»³æ¡å…‰æ›´å¥½ï¼Œæˆ‘æŠŠå¤§é–€é€²ä¾†çš„ç„é—œç‰†å…¨éƒ¨æ‰“æ‰ï¼Œç¾åœ¨ä¸€é–‹å¤§é–€å°±èƒ½ç›´æ¥çœ‹åˆ°æœ€å¾Œé¢çš„é™½å°è½åœ°çª—ï¼Œé¢¨å¯ä»¥ç›´æ¥çŒé€²ä¾†ã€‚é•·è¼©èªªé€™æ˜¯ã€ç©¿å ‚ç…ã€æœƒæ¼è²¡ï¼ŒçœŸçš„æœ‰é€™éº¼èª‡å¼µï¼Ÿ\",\n",
        "            \"ğŸ›Œ æ¨‘å£“åºŠèˆ‡é€šé¢¨\\n\\n(æ¸¬è©¦é­¯ç­ç¶“/ç¬¬46æ¢)\": \"ä¸»è‡¥å®¤å¤©èŠ±æ¿æœ‰ä¸€æ ¹æ·±åº¦ 80 å…¬åˆ†çš„è¶…å¤§æ©«æ¨‘ã€‚è¨­è¨ˆå¸«å»ºè­°ç‚ºäº†ç©ºé–“æ„Ÿï¼Œä¸è¦åšå¤©èŠ±æ¿åŒ…è¦†ï¼Œç›´æ¥æŠŠåºŠé ­æ”¾åœ¨æ¨‘ä¸‹ã€‚é€™æ¨£ç¡è¦ºæœƒä¸æœƒæœ‰å£“è¿«æ„Ÿï¼Ÿé¢¨æ°´ä¸Šæ€éº¼èªªï¼Ÿ\",\n",
        "            \"ğŸšª é–€å°é–€ç½µé–€ç…\\n\\n(æ¸¬è©¦é­¯ç­ç¶“)\": \"æˆ‘å®¶ä¸»è‡¥å®¤çš„é–€æ‰“é–‹ï¼Œå‰›å¥½æ­£å°è‘—å°é¢å°å­©æˆ¿çš„é–€ï¼Œå…©æ‰‡é–€è·é›¢åªæœ‰ 80 å…¬åˆ†ã€‚è½èªªé€™å«ã€ç½µé–€ã€æœƒå°è‡´å®¶åº­å¤±å’Œï¼Ÿå¦‚æœä¸èƒ½æ”¹é–€çš„ä½ç½®ï¼Œå¯ä»¥ç”¨è£ä¿®æ‰‹æ³•åŒ–è§£å—ï¼Ÿ\"\n",
        "        }\n",
        "        def set_prompt(text): st.session_state.prompt_content = text\n",
        "        for label, text in scenarios.items():\n",
        "            if st.button(label, use_container_width=True): set_prompt(text)\n",
        "\n",
        "# ==========================================\n",
        "# ğŸ“ ä¸»ä»‹é¢ï¼šè¼¸å…¥èˆ‡åŸ·è¡Œ\n",
        "# ==========================================\n",
        "\n",
        "user_input = st.text_area(\"éœ€æ±‚æè¿°\", height=150, key=\"prompt_content\")\n",
        "\n",
        "design_style = st.selectbox(\"æ¨¡æ“¬åœ–é¢¨æ ¼\", [\n",
        "    \"Modern Minimalist (ç¾ä»£æ¥µç°¡)\",\n",
        "    \"Industrial Loft (å·¥æ¥­é¢¨)\",\n",
        "    \"Japanese Wabi-sabi (æ—¥å¼å¯‚ä¾˜)\",\n",
        "    \"Neo-Chinese (æ–°ä¸­å¼)\",\n",
        "    \"Creamy & Cozy (æº«æ½¤å¥¶æ²¹é¢¨)\",\n",
        "    \"Scandinavian (åŒ—æ­ç°¡ç´„é¢¨)\",\n",
        "    \"Modern Luxury (ç¾ä»£è¼•å¥¢é¢¨)\",\n",
        "    \"Vintage Bauhaus (å¾©å¤åŒ…æµ©æ–¯)\",\n",
        "    \"Biophilic Design (è‡ªç„¶å…±ç”Ÿé¢¨)\",\n",
        "    \"Cyberpunk / Neo-Future (è³½åšé¾å…‹é¢¨)\"\n",
        "])\n",
        "style_en = design_style.split(\"(\")[0].strip()\n",
        "\n",
        "submit_btn = st.button(\"ğŸš€ å•Ÿå‹• HarmonyChainSpace\")\n",
        "\n",
        "if submit_btn:\n",
        "    if not api_key:\n",
        "        st.error(f\"âŒ è«‹å…ˆåœ¨å·¦å´è¼¸å…¥ {provider} API Key æ‰èƒ½å•Ÿå‹•å¤§è…¦ï¼\")\n",
        "        st.stop()\n",
        "\n",
        "    if time.time() - st.session_state.last_request < 5:\n",
        "        st.warning(\"â³ è«‹å‹¿é »ç¹æ“ä½œ...\")\n",
        "        st.stop()\n",
        "    st.session_state.last_request = time.time()\n",
        "\n",
        "    final_query = user_input + (f\"\\n(åœ–ç‰‡æè¿°ï¼š{image_desc})\" if image_desc else \"\")\n",
        "\n",
        "    with st.status(\"ğŸ¤– HarmonyChainSpace æ­£åœ¨å”ä½œä¸­...\", expanded=True) as status:\n",
        "\n",
        "        st.write(\"ğŸ“š RAG ç³»çµ±æ­£åœ¨ç¿»é–±ã€Šå»ºç¯‰æŠ€è¡“è¦å‰‡ã€‹èˆ‡ã€Šé­¯ç­ç¶“ã€‹...\")\n",
        "        context_text = core.get_rag_context(final_query)\n",
        "\n",
        "        st.write(f\"ğŸ‘·â€â™‚ï¸ [Agent 1] å»ºç¯‰å¸«æ­£åœ¨æª¢è¨æ³•è¦ ({model_name})...\")\n",
        "        try:\n",
        "            st.session_state.arch_result = core.run_architect_agent(context_text, final_query, provider, api_key, model_name)\n",
        "        except Exception as e:\n",
        "            status.update(label=\"âŒ å»ºç¯‰å¸«ç™¼ç”ŸéŒ¯èª¤\", state=\"error\")\n",
        "            st.error(f\"å»ºç¯‰å¸«éŒ¯èª¤: {e}\")\n",
        "            st.stop()\n",
        "\n",
        "        st.write(f\"ğŸ”® [Agent 2] é¢¨æ°´å¸«æ­£åœ¨æ¨ç®—å‰å‡¶ ({model_name})...\")\n",
        "        try:\n",
        "            st.session_state.fs_result = core.run_fengshui_agent(context_text, final_query, provider, api_key, model_name)\n",
        "        except Exception as e:\n",
        "            status.update(label=\"âŒ é¢¨æ°´å¸«ç™¼ç”ŸéŒ¯èª¤\", state=\"error\")\n",
        "            st.error(f\"é¢¨æ°´å¸«éŒ¯èª¤: {e}\")\n",
        "            st.stop()\n",
        "\n",
        "        st.write(f\"ğŸ¤ [Agent 3] å”èª¿è€…æ­£åœ¨æ•´åˆæ–¹æ¡ˆ ({model_name})...\")\n",
        "        try:\n",
        "            mediator_json = core.run_mediator_agent(\n",
        "                st.session_state.arch_result,\n",
        "                st.session_state.fs_result,\n",
        "                final_query,\n",
        "                style_en,\n",
        "                provider,\n",
        "                api_key,\n",
        "                model_name\n",
        "            )\n",
        "            st.session_state.mediator_result = mediator_json\n",
        "        except Exception as e:\n",
        "            status.update(label=\"âŒ å”èª¿è€…ç™¼ç”ŸéŒ¯èª¤\", state=\"error\")\n",
        "            st.error(f\"å”èª¿è€…éŒ¯èª¤: {e}\")\n",
        "            st.stop()\n",
        "\n",
        "        status.update(label=\"âœ… å”ä½œå®Œæˆï¼\", state=\"complete\", expanded=False)\n",
        "\n",
        "if st.session_state.arch_result and st.session_state.fs_result:\n",
        "    col1, col2 = st.columns(2)\n",
        "    with col1:\n",
        "        st.markdown(f\"\"\"<div class=\"bubble-card sci-bubble\"><div class=\"sci-title\">ğŸ“ å»ºç¯‰ç§‘å­¸ç ”ç©¶å“¡</div>{st.session_state.arch_result}</div>\"\"\", unsafe_allow_html=True)\n",
        "    with col2:\n",
        "        st.markdown(f\"\"\"<div class=\"bubble-card fs-bubble\"><div class=\"fs-title\">ğŸ”® é¢¨æ°´å¤§å¸«</div>{st.session_state.fs_result}</div>\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "if st.session_state.mediator_result:\n",
        "    verdict = st.session_state.mediator_result.get(\"verdict\", \"\")\n",
        "    img_prompt = st.session_state.mediator_result.get(\"design_prompt\", \"\")\n",
        "\n",
        "    st.markdown(\"<br>\", unsafe_allow_html=True)\n",
        "    st.markdown(f\"\"\"<div class=\"bubble-card mediator-bubble\"><div class=\"mediator-title\">ğŸ¤ å”èª¿è¨­è¨ˆæ–¹æ¡ˆ</div><p>{verdict.replace(chr(10), '<br>')}</p></div>\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    if paint_mode != \"é—œé–‰ç¹ªåœ–\" and img_prompt:\n",
        "        st.markdown(\"<br>\", unsafe_allow_html=True)\n",
        "        st.subheader(\"ğŸ¨ AI æ¨¡æ“¬æ•ˆæœåœ–\")\n",
        "        with st.status(\"ğŸ¨ æ­£åœ¨ç¹ªè£½æ¨¡æ“¬åœ–...\", expanded=True) as img_status:\n",
        "            img = None\n",
        "            if paint_mode == \"Pollinations (å…è²»/ç„¡é™)\":\n",
        "                st.write(\"ä½¿ç”¨ Pollinations (Flux) å¼•æ“...\")\n",
        "                img = core.generate_image_via_pollinations(img_prompt)\n",
        "            elif paint_mode == \"Hugging Face (éœ€Token)\":\n",
        "                st.write(\"ä½¿ç”¨ Hugging Face (Flux) å¼•æ“...\")\n",
        "                if not hf_token:\n",
        "                    st.error(\"è«‹åœ¨å·¦å´è¼¸å…¥ Hugging Face Token\")\n",
        "                else:\n",
        "                    img = core.generate_image_from_hf(img_prompt, hf_token)\n",
        "\n",
        "            if img:\n",
        "                img_status.update(label=\"ç¹ªåœ–å®Œæˆï¼\", state=\"complete\", expanded=False)\n",
        "                st.image(img, caption=f\"è¨­è¨ˆæ¨¡æ“¬åœ– ({paint_mode})\", use_container_width=True)\n",
        "                with st.expander(\"æŸ¥çœ‹ Prompt\"): st.code(img_prompt)\n",
        "            else:\n",
        "                img_status.update(label=\"ç¹ªåœ–å¤±æ•—\", state=\"error\")\n",
        "                st.error(\"ç¹ªåœ–å¤±æ•—ï¼Œè«‹æª¢æŸ¥ç¶²è·¯æˆ– Token\")\n",
        "\n",
        "    elif paint_mode == \"é—œé–‰ç¹ªåœ–\" and img_prompt:\n",
        "        with st.expander(\"æŸ¥çœ‹ AI ç”Ÿæˆçš„ç¹ªåœ–æŒ‡ä»¤ (æœªåŸ·è¡Œç¹ªåœ–)\"):\n",
        "            st.info(\"å·²ç•¥éç¹ªåœ–æ­¥é©Ÿã€‚\")\n",
        "            st.code(img_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inCHhoqu0i5p",
        "outputId": "ab95480a-cadb-44e1-93d2-3c482a465666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Streamlit"
      ],
      "metadata": {
        "id": "KyPCLSxJ0x4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 5. å•Ÿå‹• Streamlit ä¼ºæœå™¨\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "import time\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "# çµ‚æ­¢èˆŠçš„é€šé“ (é¿å…é‡è¤‡é–‹å•Ÿ)\n",
        "ngrok.kill()\n",
        "\n",
        "# è¨­å®š ngrok token (å¦‚æœä¸è¨­å®šï¼Œsessions æœƒå¾ˆçŸ­)\n",
        "# å»ºè­°å» ngrok å®˜ç¶²è¨»å†Šå…è²»å¸³è™Ÿï¼Œå–å¾— Authtoken\n",
        "!ngrok config add-authtoken \"36KtpysbSGt6wTAmLBA2a7LrYYf_wQvMd5xoiABW22hzkhmN\"\n",
        "\n",
        "# åœ¨èƒŒæ™¯åŸ·è¡Œ Streamlit\n",
        "get_ipython().system_raw('streamlit run app.py &')\n",
        "\n",
        "# ç­‰å¾…å¹¾ç§’è®“æœå‹™å•Ÿå‹•\n",
        "time.sleep(5)\n",
        "\n",
        "# é–‹å•Ÿé€šé“\n",
        "try:\n",
        "    # å»ºç«‹ HTTP é€šé“æŒ‡å‘ 8501 port\n",
        "    public_url = ngrok.connect(8501).public_url\n",
        "    print(f\"ğŸš€ æ‚¨çš„æ‡‰ç”¨ç¨‹å¼å·²ä¸Šç·šï¼è«‹é»æ“Šä»¥ä¸‹é€£çµï¼š\")\n",
        "    print(f\"ğŸ‘‰ {public_url}\")\n",
        "    print(\"\\n(æ³¨æ„ï¼šå¦‚æœçœ‹åˆ° ngrok çš„è­¦å‘Šé é¢ï¼Œé»æ“Š 'Visit Site' å³å¯)\")\n",
        "except Exception as e:\n",
        "    print(f\"å•Ÿå‹•å¤±æ•—ï¼Œè«‹æª¢æŸ¥ ngrok è¨­å®š: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGI4W3tFJ_vt",
        "outputId": "4713ced0-5dff-495d-a321-9fe571b4f366",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "ğŸš€ æ‚¨çš„æ‡‰ç”¨ç¨‹å¼å·²ä¸Šç·šï¼è«‹é»æ“Šä»¥ä¸‹é€£çµï¼š\n",
            "ğŸ‘‰ https://unfailed-noncompressively-nada.ngrok-free.dev\n",
            "\n",
            "(æ³¨æ„ï¼šå¦‚æœçœ‹åˆ° ngrok çš„è­¦å‘Šé é¢ï¼Œé»æ“Š 'Visit Site' å³å¯)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## å°å·¥å…·"
      ],
      "metadata": {
        "id": "b8PXLa-nYE_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "def package_final_release():\n",
        "    print(\"ğŸ“¦ æ­£åœ¨æ‰“åŒ… HarmonyChainSpace...\")\n",
        "\n",
        "    # å®šç¾©è¦æ‰“åŒ…çš„æª”æ¡ˆ\n",
        "    files_to_pack = [\n",
        "        \"app.py\",\n",
        "        \"logic.py\",\n",
        "        \"styles.py\",\n",
        "        \"requirements.txt\",\n",
        "        \"chroma_db\"\n",
        "    ]\n",
        "\n",
        "    deploy_dir = \"HarmonyChainSpace_Deploy\"\n",
        "    if os.path.exists(deploy_dir):\n",
        "        shutil.rmtree(deploy_dir)\n",
        "    os.makedirs(deploy_dir)\n",
        "\n",
        "    for item in files_to_pack:\n",
        "        if os.path.exists(item):\n",
        "            destination = os.path.join(deploy_dir, item)\n",
        "            if os.path.isdir(item):\n",
        "                shutil.copytree(item, destination)\n",
        "            else:\n",
        "                shutil.copy(item, destination)\n",
        "            print(f\"   âœ… å·²åŠ å…¥: {item}\")\n",
        "        else:\n",
        "            print(f\"   âš ï¸ è­¦å‘Š: æ‰¾ä¸åˆ° {item}\")\n",
        "\n",
        "    output_filename = \"HarmonyChainSpace_v1.0\"\n",
        "    shutil.make_archive(output_filename, 'zip', deploy_dir)\n",
        "    print(f\"ğŸ‰ æ‰“åŒ…å®Œæˆï¼è«‹ä¸‹è¼‰: {output_filename}.zip\")\n",
        "\n",
        "    files.download(f\"{output_filename}.zip\")\n",
        "\n",
        "package_final_release()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "gZZhPLwsBmjT",
        "outputId": "cc9bf5af-3138-4b9c-9488-a107bfd5fb31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¦ æ­£åœ¨æ‰“åŒ… HarmonyChainSpace...\n",
            "   âœ… å·²åŠ å…¥: app.py\n",
            "   âœ… å·²åŠ å…¥: logic.py\n",
            "   âœ… å·²åŠ å…¥: styles.py\n",
            "   âœ… å·²åŠ å…¥: requirements.txt\n",
            "   âœ… å·²åŠ å…¥: chroma_db\n",
            "ğŸ‰ æ‰“åŒ…å®Œæˆï¼è«‹ä¸‹è¼‰: HarmonyChainSpace_v1.0.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_85b69ce9-dab1-4319-bc42-78e9c2cc8318\", \"HarmonyChainSpace_v1.0.zip\", 1606059)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import google.generativeai as genai\n",
        "from huggingface_hub import InferenceClient\n",
        "from langchain_groq import ChatGroq\n",
        "from google.api_core.exceptions import ResourceExhausted, ServiceUnavailable\n",
        "\n",
        "def api_health_check():\n",
        "    print(\"ğŸ¥ é–‹å§‹ API å¥åº·æª¢æŸ¥è¨ºæ–·...\\n\")\n",
        "\n",
        "    # 1. æª¢æŸ¥ Google Gemini\n",
        "    print(\"------------------------------------------------\")\n",
        "    print(\"ğŸ¤– æª¢æŸ¥ Google Gemini API ...\")\n",
        "\n",
        "    google_key = os.environ.get(\"GOOGLE_API_KEY\")\n",
        "    if not google_key:\n",
        "        print(\"âŒ æœªæª¢æ¸¬åˆ° GOOGLE_API_KEYï¼Œè«‹å…ˆè¨­å®šç’°å¢ƒè®Šæ•¸ï¼\")\n",
        "    else:\n",
        "        genai.configure(api_key=google_key)\n",
        "        try:\n",
        "            model = genai.GenerativeModel('gemini-2.0-flash')\n",
        "            # ç™¼é€ä¸€å€‹æ¥µçŸ­çš„è«‹æ±‚ä»¥ç¯€çœ Token\n",
        "            response = model.generate_content(\"Hi\", generation_config={\"max_output_tokens\": 5})\n",
        "            print(\"âœ… ç‹€æ…‹æ­£å¸¸ï¼(Alive)\")\n",
        "            print(f\"   å›æ‡‰æ¸¬è©¦: {response.text.strip()}\")\n",
        "        except ResourceExhausted:\n",
        "            print(\"ğŸ”´ ç‹€æ…‹ç•°å¸¸ï¼šé¡åº¦å·²è€—ç›¡ (429 Resource Exhausted)\")\n",
        "            print(\"   å»ºè­°ï¼šè«‹ç­‰å¾… 1~2 åˆ†é˜å¾Œå†è©¦ï¼Œæˆ–æª¢æŸ¥ Google AI Studio é…é¡ã€‚\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ç™¼ç”Ÿå…¶ä»–éŒ¯èª¤: {e}\")\n",
        "\n",
        "    # 2. æª¢æŸ¥ Groq\n",
        "\n",
        "    print(\"------------------------------------------------\")\n",
        "    print(\"âš¡ æª¢æŸ¥ Groq API (llama-3.3-70b)...\")\n",
        "\n",
        "    groq_key = os.environ.get(\"GROQ_API_KEY\")\n",
        "    if not groq_key:\n",
        "        print(\"âŒ æœªæª¢æ¸¬åˆ° GROQ_API_KEY\")\n",
        "    else:\n",
        "        try:\n",
        "            chat = ChatGroq(\n",
        "                temperature=0,\n",
        "                model_name=\"llama-3.3-70b-versatile\",\n",
        "                groq_api_key=groq_key\n",
        "            )\n",
        "            start = time.time()\n",
        "            # é€™è£¡æˆ‘å€‘ä½¿ç”¨ invoke ä¾†æ¸¬è©¦ LangChain é€£æ¥\n",
        "            response = chat.invoke(\"Hi\")\n",
        "            duration = time.time() - start\n",
        "\n",
        "            print(f\"âœ… ç‹€æ…‹æ­£å¸¸ï¼è€—æ™‚: {duration:.2f}s\")\n",
        "            print(f\"   (LPU å¼•æ“é€šå¸¸æ‡‰å°æ–¼ 1 ç§’)\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ éŒ¯èª¤: {e}\")\n",
        "            if \"401\" in str(e):\n",
        "                print(\"ğŸ”´ åŸå› ï¼šAPI Key ç„¡æ•ˆ\")\n",
        "            elif \"429\" in str(e):\n",
        "                print(\"ğŸ”´ åŸå› ï¼šé€Ÿç‡é™åˆ¶ (Rate Limit)\")\n",
        "\n",
        "    # 2. æª¢æŸ¥ Hugging Face\n",
        "    print(\"------------------------------------------------\")\n",
        "    print(\"ğŸ¨ æª¢æŸ¥ Hugging Face API (FLUX.1-schnell)...\")\n",
        "\n",
        "    hf_token = os.environ.get(\"HF_TOKEN\")\n",
        "    if not hf_token:\n",
        "        print(\"âŒ æœªæª¢æ¸¬åˆ° HF_TOKENï¼Œè«‹å…ˆè¨­å®šç’°å¢ƒè®Šæ•¸ï¼\")\n",
        "    else:\n",
        "        try:\n",
        "            client = InferenceClient(model=\"black-forest-labs/FLUX.1-schnell\", token=hf_token)\n",
        "            # å˜—è©¦ç”Ÿæˆä¸€å¼µæ¥µå°çš„åœ–ç‰‡ (æ¸¬è©¦é€£æ¥ç”¨)\n",
        "            # é€™è£¡ä¸å¯¦éš›é¡¯ç¤ºåœ–ç‰‡ï¼Œåªè¦æ²’å ±éŒ¯å°±æ˜¯æˆåŠŸ\n",
        "            client.text_to_image(\"a dot\")\n",
        "            print(\"âœ… ç‹€æ…‹æ­£å¸¸ï¼(Alive)\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            if \"429\" in str(e):\n",
        "                print(\"ğŸ”´ ç‹€æ…‹ç•°å¸¸ï¼šè«‹æ±‚éæ–¼é »ç¹ (Rate Limit)\")\n",
        "            elif \"401\" in str(e):\n",
        "                print(\"ğŸ”´ ç‹€æ…‹ç•°å¸¸ï¼šToken ç„¡æ•ˆæˆ–æ¬Šé™ä¸è¶³\")\n",
        "\n",
        "    print(\"------------------------------------------------\")\n",
        "    print(\"è¨ºæ–·çµæŸã€‚\")\n",
        "\n",
        "# åŸ·è¡Œæª¢æŸ¥\n",
        "api_health_check()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "3m2d_ndGYGay",
        "outputId": "4b61cdf6-73db-4c7c-cae4-6d96be04b4ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ¥ é–‹å§‹ API å¥åº·æª¢æŸ¥è¨ºæ–·...\n",
            "\n",
            "------------------------------------------------\n",
            "ğŸ¤– æª¢æŸ¥ Google Gemini API ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 712.00ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âŒ ç™¼ç”Ÿå…¶ä»–éŒ¯èª¤: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n",
            "Please retry in 10.602659189s.\n",
            "------------------------------------------------\n",
            "âš¡ æª¢æŸ¥ Groq API (llama-3.3-70b)...\n",
            "âœ… ç‹€æ…‹æ­£å¸¸ï¼è€—æ™‚: 0.17s\n",
            "   (LPU å¼•æ“é€šå¸¸æ‡‰å°æ–¼ 1 ç§’)\n",
            "------------------------------------------------\n",
            "ğŸ¨ æª¢æŸ¥ Hugging Face API (FLUX.1-schnell)...\n",
            "âŒ ç™¼ç”ŸéŒ¯èª¤: 402 Client Error: Payment Required for url: https://router.huggingface.co/nebius/v1/images/generations (Request ID: Root=1-6940d756-4b1604037acb69923d2a8da7;77e3bb2e-05aa-40fd-8964-64cbbe31e4ae)\n",
            "\n",
            "You have reached the free monthly usage limit for nebius. Subscribe to PRO to get 20x more included usage, or add pre-paid credits to your account.\n",
            "------------------------------------------------\n",
            "è¨ºæ–·çµæŸã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "import os\n",
        "\n",
        "def inspect_database():\n",
        "    print(\"ğŸ” æ­£åœ¨é€²è¡Œè³‡æ–™åº« X å…‰æª¢æŸ¥...\")\n",
        "\n",
        "    persist_dir = \"./chroma_db\" # ç¢ºä¿é€™è·Ÿä½  logic.py è£¡çš„è·¯å¾‘ä¸€æ¨£\n",
        "\n",
        "    if not os.path.exists(persist_dir):\n",
        "        print(f\"âŒ åš´é‡éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°è³‡æ–™å¤¾ {persist_dir}ï¼\")\n",
        "        print(\"   åŸå› å¯èƒ½ï¼šColab é‡å•Ÿå¾Œæª”æ¡ˆè¢«æ¸…ç©ºï¼Œè«‹é‡æ–°åŸ·è¡Œ 'é‡å»ºè³‡æ–™åº«' çš„è…³æœ¬ã€‚\")\n",
        "        return\n",
        "\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
        "    db = Chroma(persist_directory=persist_dir, embedding_function=embeddings)\n",
        "\n",
        "    # å–å¾—è³‡æ–™ç¸½æ•¸\n",
        "    count = db._collection.count()\n",
        "    print(f\"ğŸ“Š è³‡æ–™åº«ç¸½ç­†æ•¸ï¼š{count} ç­†\")\n",
        "\n",
        "    if count == 0:\n",
        "        print(\"âŒ è³‡æ–™åº«æ˜¯ç©ºçš„ï¼è«‹é‡æ–°åŸ·è¡Œ Ingest è…³æœ¬ã€‚\")\n",
        "    else:\n",
        "        print(\"âœ… è³‡æ–™åº«çœ‹èµ·ä¾†æ­£å¸¸ã€‚\")\n",
        "\n",
        "        # æ¸¬è©¦æª¢ç´¢ï¼šæˆ‘å€‘ç›´æ¥å•å®ƒã€Œæ¨“æ¢¯æ‰¶æ‰‹ã€\n",
        "        print(\"\\nğŸ§ª æ¸¬è©¦æª¢ç´¢é—œéµå­—ï¼š'ç“¦æ–¯çˆ'\")\n",
        "        results = db.similarity_search(\"å»šæˆ¿ç“¦æ–¯çˆ\", k=5)\n",
        "\n",
        "        for i, doc in enumerate(results):\n",
        "            print(f\"   [{i+1}] ä¾†æºï¼š{doc.metadata.get('source')} | å…§å®¹æ‘˜è¦ï¼š{doc.page_content[:50]}...\")\n",
        "\n",
        "# åŸ·è¡Œæª¢æŸ¥\n",
        "inspect_database()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "airWabF1jHwF",
        "outputId": "ae96f339-0983-4e41-8501-9226d9efe834"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ” æ­£åœ¨é€²è¡Œè³‡æ–™åº« X å…‰æª¢æŸ¥...\n",
            "ğŸ“Š è³‡æ–™åº«ç¸½ç­†æ•¸ï¼š411 ç­†\n",
            "âœ… è³‡æ–™åº«çœ‹èµ·ä¾†æ­£å¸¸ã€‚\n",
            "\n",
            "ğŸ§ª æ¸¬è©¦æª¢ç´¢é—œéµå­—ï¼š'ç“¦æ–¯çˆ'\n",
            "   [1] ä¾†æºï¼šé­¯ç­ç¶“ | å…§å®¹æ‘˜è¦ï¼šä¸»é¡Œï¼šé–‹é–€è¦‹ç¶çš„åŒ–è§£\n",
            "å¤ç±åŸæ–‡ï¼šå»šæˆ¿ä¸å¯è¨­æ–¼æˆ¿å­æœ€å‰æ–¹ï¼ˆè¿‘å¤§é–€è™•ï¼‰ï¼Œåç‚ºã€æ¨è»Šç¶ã€ï¼Œä¸»å®¶å£ä¸å’Œï¼Œé‹å‹¢...\n",
            "   [2] ä¾†æºï¼šå»ºç¯‰æŠ€è¡“è¦å‰‡ | å…§å®¹æ‘˜è¦ï¼šç¬¬ 206 æ¢ï¼šåœ°ä¸‹å»ºç¯‰ç‰©å…§ä¸å¾—å­˜æ”¾ä½¿ç”¨æ¡¶è£æ¶²åŒ–çŸ³æ²¹æ°£ã€‚ç“¦æ–¯ä¾›æ°£ç®¡è·¯æ‡‰ä¾å·¦åˆ—è¦å®šï¼šä¸€ã€ç‡ƒæ°£ç”¨å…·æ‡‰ä½¿ç”¨...\n",
            "   [3] ä¾†æºï¼šé™½å®…ä¸‰è¦ | å…§å®¹æ‘˜è¦ï¼šä¸»é¡Œï¼šå»šæˆ¿ç„¡é çš„åŒ–è§£\n",
            "å¤ç±åŸæ–‡ï¼šç“¦æ–¯çˆå¾Œæ–¹ä¸å¯æ˜¯çª—æˆ¶ï¼Œåç‚ºã€èƒŒå¾Œç©ºè™›ã€ï¼Œä¸»æ¼è²¡ã€‚ç¶å¾Œå®œé å¯¦ç‰†ï¼Œè±¡å¾µæœ‰...\n",
            "   [4] ä¾†æºï¼šé™½å®…ä¸‰è¦ | å…§å®¹æ‘˜è¦ï¼šä¸»é¡Œï¼šé–‹é–€è¦‹ç¶çš„åŒ–è§£\n",
            "å¤ç±åŸæ–‡ï¼šé–‹é–€è¦‹ç¶ï¼ŒéŒ¢è²¡å¤šè€—ã€‚å¤§é–€ç‚ºç´æ°£ä¹‹å£ï¼Œç¶ç‚ºè²¡åº«ä¹‹è±¡ã€‚è‹¥ä¸€é€²é–€å³è¦‹ç“¦æ–¯çˆ...\n",
            "   [5] ä¾†æºï¼šå»ºç¯‰æŠ€è¡“è¦å‰‡ | å…§å®¹æ‘˜è¦ï¼šç¬¬ 211 æ¢ï¼šåœ°ä¸‹ä½¿ç”¨å–®å…ƒç­‰ä½¿ç”¨ç“¦æ–¯ä¹‹å ´æ‰€ï¼Œå‡æ‡‰è¨­ç½®å·¦åˆ—ç“¦æ–¯æ¼æ°£è‡ªå‹•è­¦å ±è¨­å‚™ï¼šä¸€ã€ç“¦æ–¯æ¼æ°£æ¢æ¸¬è¨­å‚™...\n"
          ]
        }
      ]
    }
  ]
}